{
    "docs": [
        {
            "location": "/", 
            "text": "DataFrames Documentation Outline\n\n\n\n\nPackage Manual\n\n\n\n\nGetting Started\n\n\nInstallation\n\n\nThe \nNA\n Value\n\n\nThe \nDataArray\n Type\n\n\nThe \nDataFrame\n Type\n\n\nAccessing Classic Data Sets\n\n\n\n\n\n\nImporting and Exporting (I/O)\n\n\nImporting data from tabular data files\n\n\nExporting data to a tabular data file\n\n\nSupplying \nDataFrame\ns inline with non-standard string literals\n\n\n\n\n\n\nDatabase-Style Joins\n\n\nThe Split-Apply-Combine Strategy\n\n\nReshaping and Pivoting Data\n\n\nSorting\n\n\nThe Formula, ModelFrame and ModelMatrix Types\n\n\nPooling Data (Representing Factors)\n\n\nQuerying frameworks\n\n\nQuery.jl\n\n\n\n\n\n\n\n\n\n\nAPI\n\n\n\n\nMain Types\n\n\nData Manipulation\n\n\nJoins\n\n\nReshaping\n\n\n\n\n\n\nUtilities\n\n\n\n\n\n\nDocumentation Index\n\n\n\n\nDataFrames.AbstractDataFrame\n\n\nDataFrames.DataFrame\n\n\nDataFrames.SubDataFrame\n\n\nBase.join\n\n\nDataFrames.melt\n\n\nDataFrames.meltdf\n\n\nDataFrames.stack\n\n\nDataFrames.stackdf\n\n\nDataFrames.unstack\n\n\nBase.dump\n\n\nBase.unique\n\n\nDataFrames.completecases\n\n\nDataFrames.completecases!\n\n\nDataFrames.eltypes\n\n\nDataFrames.head\n\n\nDataFrames.names!\n\n\nDataFrames.nonunique\n\n\nDataFrames.rename\n\n\nDataFrames.rename!\n\n\nDataFrames.tail\n\n\nDataFrames.unique!\n\n\nStatsBase.describe\n\n\nDataFrames.readtable\n\n\nDataFrames.writetable", 
            "title": "Introduction"
        }, 
        {
            "location": "/#dataframes-documentation-outline", 
            "text": "", 
            "title": "DataFrames Documentation Outline"
        }, 
        {
            "location": "/#package-manual", 
            "text": "Getting Started  Installation  The  NA  Value  The  DataArray  Type  The  DataFrame  Type  Accessing Classic Data Sets    Importing and Exporting (I/O)  Importing data from tabular data files  Exporting data to a tabular data file  Supplying  DataFrame s inline with non-standard string literals    Database-Style Joins  The Split-Apply-Combine Strategy  Reshaping and Pivoting Data  Sorting  The Formula, ModelFrame and ModelMatrix Types  Pooling Data (Representing Factors)  Querying frameworks  Query.jl", 
            "title": "Package Manual"
        }, 
        {
            "location": "/#api", 
            "text": "Main Types  Data Manipulation  Joins  Reshaping    Utilities", 
            "title": "API"
        }, 
        {
            "location": "/#documentation-index", 
            "text": "DataFrames.AbstractDataFrame  DataFrames.DataFrame  DataFrames.SubDataFrame  Base.join  DataFrames.melt  DataFrames.meltdf  DataFrames.stack  DataFrames.stackdf  DataFrames.unstack  Base.dump  Base.unique  DataFrames.completecases  DataFrames.completecases!  DataFrames.eltypes  DataFrames.head  DataFrames.names!  DataFrames.nonunique  DataFrames.rename  DataFrames.rename!  DataFrames.tail  DataFrames.unique!  StatsBase.describe  DataFrames.readtable  DataFrames.writetable", 
            "title": "Documentation Index"
        }, 
        {
            "location": "/man/getting_started/", 
            "text": "Getting Started\n\n\n\n\nInstallation\n\n\nThe DataFrames package is available through the Julia package system. Throughout the rest of this tutorial, we will assume that you have installed the DataFrames package and have already typed \nusing DataArrays, DataFrames\n to bring all of the relevant variables into your current namespace. In addition, we will make use of the \nRDatasets\n package, which provides access to hundreds of classical data sets.\n\n\n\n\nThe \nNA\n Value\n\n\nTo get started, let's examine the \nNA\n value. Type the following into the REPL:\n\n\nNA\n\n\n\n\n\n\nOne of the essential properties of \nNA\n is that it poisons other items. To see this, try to add something like \n1\n to \nNA\n:\n\n\n1\n \n+\n \nNA\n\n\n\n\n\n\n\n\nThe \nDataArray\n Type\n\n\nNow that we see that \nNA\n is working, let's insert one into a \nDataArray\n. We'll create one now using the \n@data\n macro:\n\n\ndv\n \n=\n \n@data\n([\nNA\n,\n \n3\n,\n \n2\n,\n \n5\n,\n \n4\n])\n\n\n\n\n\n\nTo see how \nNA\n poisons even complex calculations, let's try to take the mean of the five numbers stored in \ndv\n:\n\n\nmean\n(\ndv\n)\n\n\n\n\n\n\nIn many cases we're willing to just ignore \nNA\n values and remove them from our vector. We can do that using the \ndropna\n function:\n\n\ndropna\n(\ndv\n)\n\n\nmean\n(\ndropna\n(\ndv\n))\n\n\n\n\n\n\nInstead of removing \nNA\n values, you can try to conver the \nDataArray\n into a normal Julia \nArray\n using \nconvert\n:\n\n\nconvert\n(\nArray\n,\n \ndv\n)\n\n\n\n\n\n\nThis fails in the presence of \nNA\n values, but will succeed if there are no \nNA\n values:\n\n\ndv\n[\n1\n]\n \n=\n \n3\n\n\nconvert\n(\nArray\n,\n \ndv\n)\n\n\n\n\n\n\nIn addition to removing \nNA\n values and hoping they won't occur, you can also replace any \nNA\n values using the \nconvert\n function, which takes a replacement value as an argument:\n\n\ndv\n \n=\n \n@data\n([\nNA\n,\n \n3\n,\n \n2\n,\n \n5\n,\n \n4\n])\n\n\nmean\n(\nconvert\n(\nArray\n,\n \ndv\n,\n \n11\n))\n\n\n\n\n\n\nWhich strategy for dealing with \nNA\n values is most appropriate will typically depend on the specific details of your data analysis pathway.\n\n\nAlthough the examples above employed only 1D \nDataArray\n objects, the \nDataArray\n type defines a completely generic N-dimensional array type. Operations on generic \nDataArray\n objects work in higher dimensions in the same way that they work on Julia's Base \nArray\n type:\n\n\ndm\n \n=\n \n@data\n([\nNA\n \n0.0\n;\n \n0.0\n \n1.0\n])\n\n\ndm\n \n*\n \ndm\n\n\n\n\n\n\n\n\nThe \nDataFrame\n Type\n\n\nThe \nDataFrame\n type can be used to represent data tables, each column of which is a \nDataArray\n. You can specify the columns using keyword arguments:\n\n\ndf\n \n=\n \nDataFrame\n(\nA\n \n=\n \n1\n:\n4\n,\n \nB\n \n=\n \n[\nM\n,\n \nF\n,\n \nF\n,\n \nM\n])\n\n\n\n\n\n\nIt is also possible to construct a \nDataFrame\n in stages:\n\n\ndf\n \n=\n \nDataFrame\n()\n\n\ndf\n[\n:\nA\n]\n \n=\n \n1\n:\n8\n\n\ndf\n[\n:\nB\n]\n \n=\n \n[\nM\n,\n \nF\n,\n \nF\n,\n \nM\n,\n \nF\n,\n \nM\n,\n \nM\n,\n \nF\n]\n\n\ndf\n\n\n\n\n\n\nThe \nDataFrame\n we build in this way has 8 rows and 2 columns. You can check this using \nsize\n function:\n\n\nnrows\n \n=\n \nsize\n(\ndf\n,\n \n1\n)\n\n\nncols\n \n=\n \nsize\n(\ndf\n,\n \n2\n)\n\n\n\n\n\n\nWe can also look at small subsets of the data in a couple of different ways:\n\n\nhead\n(\ndf\n)\n\n\ntail\n(\ndf\n)\n\n\n\ndf\n[\n1\n:\n3\n,\n \n:\n]\n\n\n\n\n\n\nHaving seen what some of the rows look like, we can try to summarize the entire data set using \ndescribe\n:\n\n\ndescribe\n(\ndf\n)\n\n\n\n\n\n\nTo focus our search, we start looking at just the means and medians of specific columns. In the example below, we use numeric indexing to access the columns of the \nDataFrame\n:\n\n\nmean\n(\ndf\n[\n1\n])\n\n\nmedian\n(\ndf\n[\n1\n])\n\n\n\n\n\n\nWe could also have used column names to access individual columns:\n\n\nmean\n(\ndf\n[\n:\nA\n])\n\n\nmedian\n(\ndf\n[\n:\nA\n])\n\n\n\n\n\n\nWe can also apply a function to each column of a \nDataFrame\n with the \ncolwise\n function. For example:\n\n\ndf\n \n=\n \nDataFrame\n(\nA\n \n=\n \n1\n:\n4\n,\n \nB\n \n=\n \nrandn\n(\n4\n))\n\n\ncolwise\n(\ncumsum\n,\n \ndf\n)\n\n\n\n\n\n\n\n\nAccessing Classic Data Sets\n\n\nTo see more of the functionality for working with \nDataFrame\n objects, we need a more complex data set to work with. We'll use the \nRDatasets\n package, which provides access to many of the classical data sets that are available in R.\n\n\nFor example, we can access Fisher's iris data set using the following functions:\n\n\nusing\n \nRDatasets\n\n\niris\n \n=\n \ndataset\n(\ndatasets\n,\n \niris\n)\n\n\nhead\n(\niris\n)\n\n\n\n\n\n\nIn the next section, we'll discuss generic I/O strategy for reading and writing \nDataFrame\n objects that you can use to import and export your own data files.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/man/getting_started/#getting-started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/man/getting_started/#installation", 
            "text": "The DataFrames package is available through the Julia package system. Throughout the rest of this tutorial, we will assume that you have installed the DataFrames package and have already typed  using DataArrays, DataFrames  to bring all of the relevant variables into your current namespace. In addition, we will make use of the  RDatasets  package, which provides access to hundreds of classical data sets.", 
            "title": "Installation"
        }, 
        {
            "location": "/man/getting_started/#the-na-value", 
            "text": "To get started, let's examine the  NA  value. Type the following into the REPL:  NA   One of the essential properties of  NA  is that it poisons other items. To see this, try to add something like  1  to  NA :  1   +   NA", 
            "title": "The NA Value"
        }, 
        {
            "location": "/man/getting_started/#the-dataarray-type", 
            "text": "Now that we see that  NA  is working, let's insert one into a  DataArray . We'll create one now using the  @data  macro:  dv   =   @data ([ NA ,   3 ,   2 ,   5 ,   4 ])   To see how  NA  poisons even complex calculations, let's try to take the mean of the five numbers stored in  dv :  mean ( dv )   In many cases we're willing to just ignore  NA  values and remove them from our vector. We can do that using the  dropna  function:  dropna ( dv )  mean ( dropna ( dv ))   Instead of removing  NA  values, you can try to conver the  DataArray  into a normal Julia  Array  using  convert :  convert ( Array ,   dv )   This fails in the presence of  NA  values, but will succeed if there are no  NA  values:  dv [ 1 ]   =   3  convert ( Array ,   dv )   In addition to removing  NA  values and hoping they won't occur, you can also replace any  NA  values using the  convert  function, which takes a replacement value as an argument:  dv   =   @data ([ NA ,   3 ,   2 ,   5 ,   4 ])  mean ( convert ( Array ,   dv ,   11 ))   Which strategy for dealing with  NA  values is most appropriate will typically depend on the specific details of your data analysis pathway.  Although the examples above employed only 1D  DataArray  objects, the  DataArray  type defines a completely generic N-dimensional array type. Operations on generic  DataArray  objects work in higher dimensions in the same way that they work on Julia's Base  Array  type:  dm   =   @data ([ NA   0.0 ;   0.0   1.0 ])  dm   *   dm", 
            "title": "The DataArray Type"
        }, 
        {
            "location": "/man/getting_started/#the-dataframe-type", 
            "text": "The  DataFrame  type can be used to represent data tables, each column of which is a  DataArray . You can specify the columns using keyword arguments:  df   =   DataFrame ( A   =   1 : 4 ,   B   =   [ M ,   F ,   F ,   M ])   It is also possible to construct a  DataFrame  in stages:  df   =   DataFrame ()  df [ : A ]   =   1 : 8  df [ : B ]   =   [ M ,   F ,   F ,   M ,   F ,   M ,   M ,   F ]  df   The  DataFrame  we build in this way has 8 rows and 2 columns. You can check this using  size  function:  nrows   =   size ( df ,   1 )  ncols   =   size ( df ,   2 )   We can also look at small subsets of the data in a couple of different ways:  head ( df )  tail ( df )  df [ 1 : 3 ,   : ]   Having seen what some of the rows look like, we can try to summarize the entire data set using  describe :  describe ( df )   To focus our search, we start looking at just the means and medians of specific columns. In the example below, we use numeric indexing to access the columns of the  DataFrame :  mean ( df [ 1 ])  median ( df [ 1 ])   We could also have used column names to access individual columns:  mean ( df [ : A ])  median ( df [ : A ])   We can also apply a function to each column of a  DataFrame  with the  colwise  function. For example:  df   =   DataFrame ( A   =   1 : 4 ,   B   =   randn ( 4 ))  colwise ( cumsum ,   df )", 
            "title": "The DataFrame Type"
        }, 
        {
            "location": "/man/getting_started/#accessing-classic-data-sets", 
            "text": "To see more of the functionality for working with  DataFrame  objects, we need a more complex data set to work with. We'll use the  RDatasets  package, which provides access to many of the classical data sets that are available in R.  For example, we can access Fisher's iris data set using the following functions:  using   RDatasets  iris   =   dataset ( datasets ,   iris )  head ( iris )   In the next section, we'll discuss generic I/O strategy for reading and writing  DataFrame  objects that you can use to import and export your own data files.", 
            "title": "Accessing Classic Data Sets"
        }, 
        {
            "location": "/man/io/", 
            "text": "Importing and Exporting (I/O)\n\n\n\n\nImporting data from tabular data files\n\n\nTo read data from a CSV-like file, use the \nreadtable\n function:\n\n\n#\n\n\nDataFrames.readtable\n \n \nFunction\n.\n\n\nRead data from a tabular-file format (CSV, TSV, ...)\n\n\nreadtable\n(\nfilename\n,\n \n[\nkeyword\n \noptions\n])\n\n\n\n\n\n\nArguments\n\n\n\n\nfilename::AbstractString\n : the filename to be read\n\n\n\n\nKeyword Arguments\n\n\n\n\nheader::Bool\n \u2013 Use the information from the file's header line to determine column names. Defaults to \ntrue\n.\n\n\nseparator::Char\n \u2013 Assume that fields are split by the \nseparator\n character. If not specified, it will be guessed from the filename: \n.csv\n defaults to \n','\n, \n.tsv\n defaults to \n'  '\n, \n.wsv\n defaults to \n' '\n.\n\n\nquotemark::Vector{Char}\n \u2013 Assume that fields contained inside of two \nquotemark\n characters are quoted, which disables processing of separators and linebreaks. Set to \nChar[]\n to disable this feature and slightly improve performance. Defaults to \n['\"']\n.\n\n\ndecimal::Char\n \u2013 Assume that the decimal place in numbers is written using the \ndecimal\n character. Defaults to \n'.'\n.\n\n\nnastrings::Vector{String}\n \u2013 Translate any of the strings into this vector into an \nNA\n. Defaults to \n[\"\", \"NA\"]\n.\n\n\ntruestrings::Vector{String}\n \u2013 Translate any of the strings into this vector into a Boolean \ntrue\n. Defaults to \n[\"T\", \"t\", \"TRUE\", \"true\"]\n.\n\n\nfalsestrings::Vector{String}\n \u2013 Translate any of the strings into this vector into a Boolean \nfalse\n. Defaults to \n[\"F\", \"f\", \"FALSE\", \"false\"]\n.\n\n\nmakefactors::Bool\n \u2013 Convert string columns into \nPooledDataVector\n's for use as factors. Defaults to \nfalse\n.\n\n\nnrows::Int\n \u2013 Read only \nnrows\n from the file. Defaults to \n-1\n, which indicates that the entire file should be read.\n\n\nnames::Vector{Symbol}\n \u2013 Use the values in this array as the names for all columns instead of or in lieu of the names in the file's header. Defaults to \n[]\n, which indicates that the header should be used if present or that numeric names should be invented if there is no header.\n\n\neltypes::Vector\n \u2013 Specify the types of all columns. Defaults to \n[]\n.\n\n\nallowcomments::Bool\n \u2013 Ignore all text inside comments. Defaults to \nfalse\n.\n\n\ncommentmark::Char\n \u2013 Specify the character that starts comments. Defaults to \n'#'\n.\n\n\nignorepadding::Bool\n \u2013 Ignore all whitespace on left and right sides of a field. Defaults to \ntrue\n.\n\n\nskipstart::Int\n \u2013 Specify the number of initial rows to skip. Defaults to \n0\n.\n\n\nskiprows::Vector{Int}\n \u2013 Specify the indices of lines in the input to ignore. Defaults to \n[]\n.\n\n\nskipblanks::Bool\n \u2013 Skip any blank lines in input. Defaults to \ntrue\n.\n\n\nencoding::Symbol\n \u2013 Specify the file's encoding as either \n:utf8\n or \n:latin1\n. Defaults to \n:utf8\n.\n\n\nnormalizenames::Bool\n \u2013 Ensure that column names are valid Julia identifiers. For instance this renames a column named \n\"a b\"\n to \n\"a_b\"\n which can then be accessed with \n:a_b\n instead of \nSymbol(\"a b\")\n. Defaults to \ntrue\n.\n\n\n\n\nResult\n\n\n\n\n::DataFrame\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nreadtable\n(\ndata.csv\n)\n\n\ndf\n \n=\n \nreadtable\n(\ndata.tsv\n)\n\n\ndf\n \n=\n \nreadtable\n(\ndata.wsv\n)\n\n\ndf\n \n=\n \nreadtable\n(\ndata.txt\n,\n \nseparator\n \n=\n \n    \n)\n\n\ndf\n \n=\n \nreadtable\n(\ndata.txt\n,\n \nheader\n \n=\n \nfalse\n)\n\n\n\n\n\n\nsource\n\n\nreadtable\n requires that you specify the path of the file that you would like to read as a \nString\n. To read data from a non-file source, you may also supply an \nIO\n object. It supports many additional keyword arguments: these are documented in the section on advanced I/O operations.\n\n\n\n\nExporting data to a tabular data file\n\n\nTo write data to a CSV file, use the \nwritetable\n function:\n\n\n#\n\n\nDataFrames.writetable\n \n \nFunction\n.\n\n\nWrite data to a tabular-file format (CSV, TSV, ...)\n\n\nwritetable\n(\nfilename\n,\n \ndf\n,\n \n[\nkeyword\n \noptions\n])\n\n\n\n\n\n\nArguments\n\n\n\n\nfilename::AbstractString\n : the filename to be created\n\n\ndf::AbstractDataFrame\n : the AbstractDataFrame to be written\n\n\n\n\nKeyword Arguments\n\n\n\n\nseparator::Char\n \u2013 The separator character that you would like to use. Defaults to the output of \ngetseparator(filename)\n, which uses commas for files that end in \n.csv\n, tabs for files that end in \n.tsv\n and a single space for files that end in \n.wsv\n.\n\n\nquotemark::Char\n \u2013 The character used to delimit string fields. Defaults to \n'\"'\n.\n\n\nheader::Bool\n \u2013 Should the file contain a header that specifies the column names from \ndf\n. Defaults to \ntrue\n.\n\n\nnastring::AbstractString\n \u2013 What to write in place of missing data. Defaults to \n\"NA\"\n.\n\n\n\n\nResult\n\n\n\n\n::DataFrame\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\nA\n \n=\n \n1\n:\n10\n)\n\n\nwritetable\n(\noutput.csv\n,\n \ndf\n)\n\n\nwritetable\n(\noutput.dat\n,\n \ndf\n,\n \nseparator\n \n=\n \n,\n,\n \nheader\n \n=\n \nfalse\n)\n\n\nwritetable\n(\noutput.dat\n,\n \ndf\n,\n \nquotemark\n \n=\n \n,\n \nseparator\n \n=\n \n,\n)\n\n\nwritetable\n(\noutput.dat\n,\n \ndf\n,\n \nheader\n \n=\n \nfalse\n)\n\n\n\n\n\n\nsource\n\n\n\n\nSupplying \nDataFrame\ns inline with non-standard string literals\n\n\nYou can also provide CSV-like tabular data in a non-standard string literal to construct a new \nDataFrame\n, as in the following:\n\n\ndf\n \n=\n \ncsv\n\n\n    name,  age, squidPerWeek\n\n\n    Alice,  36,         3.14\n\n\n    Bob,    24,         0\n\n\n    Carol,  58,         2.71\n\n\n    Eve,    49,         7.77\n\n\n    \n\n\n\n\n\n\nThe \ncsv\n string literal prefix indicates that the data are supplied in standard comma-separated value format. Common alternative formats are also available as string literals. For semicolon-separated values, with comma as a decimal, use \ncsv2\n:\n\n\ndf\n \n=\n \ncsv2\n\n\n    name;  age; squidPerWeek\n\n\n    Alice;  36;         3,14\n\n\n    Bob;    24;         0\n\n\n    Carol;  58;         2,71\n\n\n    Eve;    49;         7,77\n\n\n    \n\n\n\n\n\n\nFor whitespace-separated values, use \nwsv\n:\n\n\ndf\n \n=\n \nwsv\n\n\n    name  age squidPerWeek\n\n\n    Alice  36         3.14\n\n\n    Bob    24         0\n\n\n    Carol  58         2.71\n\n\n    Eve    49         7.77\n\n\n    \n\n\n\n\n\n\nAnd for tab-separated values, use \ntsv\n:\n\n\ndf\n \n=\n \ntsv\n\n\n    name    age squidPerWeek\n\n\n    Alice   36  3.14\n\n\n    Bob 24  0\n\n\n    Carol   58  2.71\n\n\n    Eve 49  7.77", 
            "title": "IO"
        }, 
        {
            "location": "/man/io/#importing-and-exporting-io", 
            "text": "", 
            "title": "Importing and Exporting (I/O)"
        }, 
        {
            "location": "/man/io/#importing-data-from-tabular-data-files", 
            "text": "To read data from a CSV-like file, use the  readtable  function:  #  DataFrames.readtable     Function .  Read data from a tabular-file format (CSV, TSV, ...)  readtable ( filename ,   [ keyword   options ])   Arguments   filename::AbstractString  : the filename to be read   Keyword Arguments   header::Bool  \u2013 Use the information from the file's header line to determine column names. Defaults to  true .  separator::Char  \u2013 Assume that fields are split by the  separator  character. If not specified, it will be guessed from the filename:  .csv  defaults to  ',' ,  .tsv  defaults to  '  ' ,  .wsv  defaults to  ' ' .  quotemark::Vector{Char}  \u2013 Assume that fields contained inside of two  quotemark  characters are quoted, which disables processing of separators and linebreaks. Set to  Char[]  to disable this feature and slightly improve performance. Defaults to  ['\"'] .  decimal::Char  \u2013 Assume that the decimal place in numbers is written using the  decimal  character. Defaults to  '.' .  nastrings::Vector{String}  \u2013 Translate any of the strings into this vector into an  NA . Defaults to  [\"\", \"NA\"] .  truestrings::Vector{String}  \u2013 Translate any of the strings into this vector into a Boolean  true . Defaults to  [\"T\", \"t\", \"TRUE\", \"true\"] .  falsestrings::Vector{String}  \u2013 Translate any of the strings into this vector into a Boolean  false . Defaults to  [\"F\", \"f\", \"FALSE\", \"false\"] .  makefactors::Bool  \u2013 Convert string columns into  PooledDataVector 's for use as factors. Defaults to  false .  nrows::Int  \u2013 Read only  nrows  from the file. Defaults to  -1 , which indicates that the entire file should be read.  names::Vector{Symbol}  \u2013 Use the values in this array as the names for all columns instead of or in lieu of the names in the file's header. Defaults to  [] , which indicates that the header should be used if present or that numeric names should be invented if there is no header.  eltypes::Vector  \u2013 Specify the types of all columns. Defaults to  [] .  allowcomments::Bool  \u2013 Ignore all text inside comments. Defaults to  false .  commentmark::Char  \u2013 Specify the character that starts comments. Defaults to  '#' .  ignorepadding::Bool  \u2013 Ignore all whitespace on left and right sides of a field. Defaults to  true .  skipstart::Int  \u2013 Specify the number of initial rows to skip. Defaults to  0 .  skiprows::Vector{Int}  \u2013 Specify the indices of lines in the input to ignore. Defaults to  [] .  skipblanks::Bool  \u2013 Skip any blank lines in input. Defaults to  true .  encoding::Symbol  \u2013 Specify the file's encoding as either  :utf8  or  :latin1 . Defaults to  :utf8 .  normalizenames::Bool  \u2013 Ensure that column names are valid Julia identifiers. For instance this renames a column named  \"a b\"  to  \"a_b\"  which can then be accessed with  :a_b  instead of  Symbol(\"a b\") . Defaults to  true .   Result   ::DataFrame   Examples  df   =   readtable ( data.csv )  df   =   readtable ( data.tsv )  df   =   readtable ( data.wsv )  df   =   readtable ( data.txt ,   separator   =        )  df   =   readtable ( data.txt ,   header   =   false )   source  readtable  requires that you specify the path of the file that you would like to read as a  String . To read data from a non-file source, you may also supply an  IO  object. It supports many additional keyword arguments: these are documented in the section on advanced I/O operations.", 
            "title": "Importing data from tabular data files"
        }, 
        {
            "location": "/man/io/#exporting-data-to-a-tabular-data-file", 
            "text": "To write data to a CSV file, use the  writetable  function:  #  DataFrames.writetable     Function .  Write data to a tabular-file format (CSV, TSV, ...)  writetable ( filename ,   df ,   [ keyword   options ])   Arguments   filename::AbstractString  : the filename to be created  df::AbstractDataFrame  : the AbstractDataFrame to be written   Keyword Arguments   separator::Char  \u2013 The separator character that you would like to use. Defaults to the output of  getseparator(filename) , which uses commas for files that end in  .csv , tabs for files that end in  .tsv  and a single space for files that end in  .wsv .  quotemark::Char  \u2013 The character used to delimit string fields. Defaults to  '\"' .  header::Bool  \u2013 Should the file contain a header that specifies the column names from  df . Defaults to  true .  nastring::AbstractString  \u2013 What to write in place of missing data. Defaults to  \"NA\" .   Result   ::DataFrame   Examples  df   =   DataFrame ( A   =   1 : 10 )  writetable ( output.csv ,   df )  writetable ( output.dat ,   df ,   separator   =   , ,   header   =   false )  writetable ( output.dat ,   df ,   quotemark   =   ,   separator   =   , )  writetable ( output.dat ,   df ,   header   =   false )   source", 
            "title": "Exporting data to a tabular data file"
        }, 
        {
            "location": "/man/io/#supplying-dataframes-inline-with-non-standard-string-literals", 
            "text": "You can also provide CSV-like tabular data in a non-standard string literal to construct a new  DataFrame , as in the following:  df   =   csv      name,  age, squidPerWeek      Alice,  36,         3.14      Bob,    24,         0      Carol,  58,         2.71      Eve,    49,         7.77         The  csv  string literal prefix indicates that the data are supplied in standard comma-separated value format. Common alternative formats are also available as string literals. For semicolon-separated values, with comma as a decimal, use  csv2 :  df   =   csv2      name;  age; squidPerWeek      Alice;  36;         3,14      Bob;    24;         0      Carol;  58;         2,71      Eve;    49;         7,77         For whitespace-separated values, use  wsv :  df   =   wsv      name  age squidPerWeek      Alice  36         3.14      Bob    24         0      Carol  58         2.71      Eve    49         7.77         And for tab-separated values, use  tsv :  df   =   tsv      name    age squidPerWeek      Alice   36  3.14      Bob 24  0      Carol   58  2.71      Eve 49  7.77", 
            "title": "Supplying DataFrames inline with non-standard string literals"
        }, 
        {
            "location": "/man/joins/", 
            "text": "Database-Style Joins\n\n\nWe often need to combine two or more data sets together to provide a complete picture of the topic we are studying. For example, suppose that we have the following two data sets:\n\n\nnames\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n20\n,\n \n40\n],\n \nName\n \n=\n \n[\nJohn Doe\n,\n \nJane Doe\n])\n\n\njobs\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n20\n,\n \n40\n],\n \nJob\n \n=\n \n[\nLawyer\n,\n \nDoctor\n])\n\n\n\n\n\n\nWe might want to work with a larger data set that contains both the names and jobs for each ID. We can do this using the \njoin\n function:\n\n\nfull\n \n=\n \njoin\n(\nnames\n,\n \njobs\n,\n \non\n \n=\n \n:\nID\n)\n\n\n\n\n\n\nOutput:\n\n\n\n\n\n\n\n\nRow\n\n\nID\n\n\nName\n\n\nJob\n\n\n\n\n\n\n\n\n\n\n1\n\n\n20\n\n\n\"John Doe\"\n\n\n\"Lawyer\"\n\n\n\n\n\n\n2\n\n\n40\n\n\n\"Jane Doe\"\n\n\n\"Doctor\"\n\n\n\n\n\n\n\n\nIn relational database theory, this operation is generally referred to as a join. The columns used to determine which rows should be combined during a join are called keys.\n\n\nThere are seven kinds of joins supported by the DataFrames package:\n\n\n\n\nInner: The output contains rows for values of the key that exist in both the first (left) and second (right) arguments to \njoin\n.\n\n\nLeft: The output contains rows for values of the key that exist in the first (left) argument to \njoin\n, whether or not that value exists in the second (right) argument.\n\n\nRight: The output contains rows for values of the key that exist in the second (right) argument to \njoin\n, whether or not that value exists in the first (left) argument.\n\n\nOuter: The output contains rows for values of the key that exist in the first (left) or second (right) argument to \njoin\n.\n\n\nSemi: Like an inner join, but output is restricted to columns from the first (left) argument to \njoin\n.\n\n\nAnti: The output contains rows for values of the key that exist in the first (left) but not the second (right) argument to \njoin\n. As with semi joins, output is restricted to columns from the first (left) argument.\n\n\nCross: The output is the cartesian product of rows from the first (left) and second (right) arguments to \njoin\n.\n\n\n\n\nYou can control the kind of join that \njoin\n performs using the \nkind\n keyword argument:\n\n\na\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n20\n,\n \n40\n],\n \nName\n \n=\n \n[\nJohn Doe\n,\n \nJane Doe\n])\n\n\nb\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n20\n,\n \n60\n],\n \nJob\n \n=\n \n[\nLawyer\n,\n \nAstronaut\n])\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\ninner\n)\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nleft\n)\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nright\n)\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nouter\n)\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nsemi\n)\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nanti\n)\n\n\n\n\n\n\nCross joins are the only kind of join that does not use a key:\n\n\njoin\n(\na\n,\n \nb\n,\n \nkind\n \n=\n \n:\ncross\n)", 
            "title": "Joins"
        }, 
        {
            "location": "/man/joins/#database-style-joins", 
            "text": "We often need to combine two or more data sets together to provide a complete picture of the topic we are studying. For example, suppose that we have the following two data sets:  names   =   DataFrame ( ID   =   [ 20 ,   40 ],   Name   =   [ John Doe ,   Jane Doe ])  jobs   =   DataFrame ( ID   =   [ 20 ,   40 ],   Job   =   [ Lawyer ,   Doctor ])   We might want to work with a larger data set that contains both the names and jobs for each ID. We can do this using the  join  function:  full   =   join ( names ,   jobs ,   on   =   : ID )   Output:     Row  ID  Name  Job      1  20  \"John Doe\"  \"Lawyer\"    2  40  \"Jane Doe\"  \"Doctor\"     In relational database theory, this operation is generally referred to as a join. The columns used to determine which rows should be combined during a join are called keys.  There are seven kinds of joins supported by the DataFrames package:   Inner: The output contains rows for values of the key that exist in both the first (left) and second (right) arguments to  join .  Left: The output contains rows for values of the key that exist in the first (left) argument to  join , whether or not that value exists in the second (right) argument.  Right: The output contains rows for values of the key that exist in the second (right) argument to  join , whether or not that value exists in the first (left) argument.  Outer: The output contains rows for values of the key that exist in the first (left) or second (right) argument to  join .  Semi: Like an inner join, but output is restricted to columns from the first (left) argument to  join .  Anti: The output contains rows for values of the key that exist in the first (left) but not the second (right) argument to  join . As with semi joins, output is restricted to columns from the first (left) argument.  Cross: The output is the cartesian product of rows from the first (left) and second (right) arguments to  join .   You can control the kind of join that  join  performs using the  kind  keyword argument:  a   =   DataFrame ( ID   =   [ 20 ,   40 ],   Name   =   [ John Doe ,   Jane Doe ])  b   =   DataFrame ( ID   =   [ 20 ,   60 ],   Job   =   [ Lawyer ,   Astronaut ])  join ( a ,   b ,   on   =   : ID ,   kind   =   : inner )  join ( a ,   b ,   on   =   : ID ,   kind   =   : left )  join ( a ,   b ,   on   =   : ID ,   kind   =   : right )  join ( a ,   b ,   on   =   : ID ,   kind   =   : outer )  join ( a ,   b ,   on   =   : ID ,   kind   =   : semi )  join ( a ,   b ,   on   =   : ID ,   kind   =   : anti )   Cross joins are the only kind of join that does not use a key:  join ( a ,   b ,   kind   =   : cross )", 
            "title": "Database-Style Joins"
        }, 
        {
            "location": "/man/split_apply_combine/", 
            "text": "The Split-Apply-Combine Strategy\n\n\nMany data analysis tasks involve splitting a data set into groups, applying some functions to each of the groups and then combining the results. A standardized framework for handling this sort of computation is described in the paper, The Split-Apply-Combine Strategy for Data Analysis \\\nhttp://www.jstatsoft.org/v40/i01\n>, written by Hadley Wickham.\n\n\nThe DataFrames package supports the Split-Apply-Combine strategy through the \nby\n function, which takes in three arguments: (1) a DataFrame, (2) one or more columns to split the DataFrame on, and (3) a function or expression to apply to each subset of the DataFrame.\n\n\nWe show several examples of the \nby\n function applied to the \niris\n dataset below:\n\n\nusing\n \nDataFrames\n,\n \nRDatasets\n\n\n\niris\n \n=\n \ndataset\n(\ndatasets\n,\n \niris\n)\n\n\n\nby\n(\niris\n,\n \n:\nSpecies\n,\n \nsize\n)\n\n\nby\n(\niris\n,\n \n:\nSpecies\n,\n \ndf\n \n-\n \nmean\n(\ndf\n[\n:\nPetalLength\n]))\n\n\nby\n(\niris\n,\n \n:\nSpecies\n,\n \ndf\n \n-\n \nDataFrame\n(\nN\n \n=\n \nsize\n(\ndf\n,\n \n1\n)))\n\n\n\n\n\n\nThe \nby\n function also support the \ndo\n block form:\n\n\nby\n(\niris\n,\n \n:\nSpecies\n)\n \ndo\n \ndf\n\n   \nDataFrame\n(\nm\n \n=\n \nmean\n(\ndf\n[\n:\nPetalLength\n]),\n \ns\u00b2\n \n=\n \nvar\n(\ndf\n[\n:\nPetalLength\n]))\n\n\nend\n\n\n\n\n\n\nA second approach to the Split-Apply-Combine strategy is implemented in the \naggregate\n function, which also takes three arguments: (1) a DataFrame, (2) one or more columns to split the DataFrame on, and a (3) function (or several functions) that are used to compute a summary of each subset of the DataFrame. Each function is applied to each column, that was not used to split the DataFrame, creating new columns of the form \n$name_$function\n e.g. \nSepalLength_mean\n. Anonymous functions and expressions that do not have a name will be called \n\u03bb1\n.\n\n\nWe show several examples of the \naggregate\n function applied to the \niris\n dataset below:\n\n\naggregate\n(\niris\n,\n \n:\nSpecies\n,\n \nsum\n)\n\n\naggregate\n(\niris\n,\n \n:\nSpecies\n,\n \n[\nsum\n,\n \nmean\n])\n\n\n\n\n\n\nIf you only want to split the data set into subsets, use the \ngroupby\n function:\n\n\nfor\n \nsubdf\n \nin\n \ngroupby\n(\niris\n,\n \n:\nSpecies\n)\n\n    \nprintln\n(\nsize\n(\nsubdf\n,\n \n1\n))\n\n\nend", 
            "title": "Split-apply-combine"
        }, 
        {
            "location": "/man/split_apply_combine/#the-split-apply-combine-strategy", 
            "text": "Many data analysis tasks involve splitting a data set into groups, applying some functions to each of the groups and then combining the results. A standardized framework for handling this sort of computation is described in the paper, The Split-Apply-Combine Strategy for Data Analysis \\ http://www.jstatsoft.org/v40/i01 >, written by Hadley Wickham.  The DataFrames package supports the Split-Apply-Combine strategy through the  by  function, which takes in three arguments: (1) a DataFrame, (2) one or more columns to split the DataFrame on, and (3) a function or expression to apply to each subset of the DataFrame.  We show several examples of the  by  function applied to the  iris  dataset below:  using   DataFrames ,   RDatasets  iris   =   dataset ( datasets ,   iris )  by ( iris ,   : Species ,   size )  by ( iris ,   : Species ,   df   -   mean ( df [ : PetalLength ]))  by ( iris ,   : Species ,   df   -   DataFrame ( N   =   size ( df ,   1 )))   The  by  function also support the  do  block form:  by ( iris ,   : Species )   do   df \n    DataFrame ( m   =   mean ( df [ : PetalLength ]),   s\u00b2   =   var ( df [ : PetalLength ]))  end   A second approach to the Split-Apply-Combine strategy is implemented in the  aggregate  function, which also takes three arguments: (1) a DataFrame, (2) one or more columns to split the DataFrame on, and a (3) function (or several functions) that are used to compute a summary of each subset of the DataFrame. Each function is applied to each column, that was not used to split the DataFrame, creating new columns of the form  $name_$function  e.g.  SepalLength_mean . Anonymous functions and expressions that do not have a name will be called  \u03bb1 .  We show several examples of the  aggregate  function applied to the  iris  dataset below:  aggregate ( iris ,   : Species ,   sum )  aggregate ( iris ,   : Species ,   [ sum ,   mean ])   If you only want to split the data set into subsets, use the  groupby  function:  for   subdf   in   groupby ( iris ,   : Species ) \n     println ( size ( subdf ,   1 ))  end", 
            "title": "The Split-Apply-Combine Strategy"
        }, 
        {
            "location": "/man/reshaping_and_pivoting/", 
            "text": "Reshaping and Pivoting Data\n\n\nReshape data from wide to long format using the \nstack\n function:\n\n\nusing\n \nDataFrames\n,\n \nRDatasets\n\n\niris\n \n=\n \ndataset\n(\ndatasets\n,\n \niris\n)\n\n\niris\n[\n:\nid\n]\n \n=\n \n1\n:\nsize\n(\niris\n,\n \n1\n)\n  \n# this makes it easier to unstack\n\n\nd\n \n=\n \nstack\n(\niris\n,\n \n1\n:\n4\n)\n\n\n\n\n\n\nThe second optional argument to \nstack\n indicates the columns to be stacked. These are normally referred to as the measured variables. Column names can also be given:\n\n\nd\n \n=\n \nstack\n(\niris\n,\n \n[\n:\nSepalLength\n,\n \n:\nSepalWidth\n,\n \n:\nPetalLength\n,\n \n:\nPetalWidth\n])\n\n\n\n\n\n\nNote that all columns can be of different types. Type promotion follows the rules of \nvcat\n.\n\n\nThe stacked DataFrame that results includes all of the columns not specified to be stacked. These are repeated for each stacked column. These are normally refered to as identifier (id) columns. In addition to the id columns, two additional columns labeled \n:variable\n and \n:values\n contain the column identifier and the stacked columns.\n\n\nA third optional argument to \nstack\n represents the id columns that are repeated. This makes it easier to specify which variables you want included in the long format:\n\n\nd\n \n=\n \nstack\n(\niris\n,\n \n[\n:\nSepalLength\n,\n \n:\nSepalWidth\n],\n \n:\nSpecies\n)\n\n\n\n\n\n\nmelt\n is an alternative function to reshape from wide to long format. It is based on \nstack\n, but it prefers specification of the id columns as:\n\n\nd\n \n=\n \nmelt\n(\niris\n,\n \n:\nSpecies\n)\n\n\n\n\n\n\nAll other columns are assumed to be measured variables (they are stacked).\n\n\nYou can also stack an entire DataFrame. The default stacks all floating-point columns:\n\n\nd\n \n=\n \nstack\n(\niris\n)\n\n\n\n\n\n\nunstack\n converts from a long format to a wide format. The default is requires specifying which columns are an id variable, column variable names, and column values:\n\n\nlongdf\n \n=\n \nmelt\n(\niris\n,\n \n[\n:\nSpecies\n,\n \n:\nid\n])\n\n\nwidedf\n \n=\n \nunstack\n(\nlongdf\n,\n \n:\nid\n,\n \n:\nvariable\n,\n \n:\nvalue\n)\n\n\n\n\n\n\nIf the remaining columns are unique, you can skip the id variable and use:\n\n\nwidedf\n \n=\n \nunstack\n(\nlongdf\n,\n \n:\nvariable\n,\n \n:\nvalue\n)\n\n\n\n\n\n\nstackdf\n and \nmeltdf\n are two additional functions that work like \nstack\n and \nmelt\n, but they provide a view into the original wide DataFrame. Here is an example:\n\n\nd\n \n=\n \nstackdf\n(\niris\n)\n\n\n\n\n\n\nThis saves memory. To create the view, several AbstractVectors are defined:\n\n\n:variable\n column \u2013 \nEachRepeatedVector\n   This repeats the variables N times where N is the number of rows of the original AbstractDataFrame.\n\n\n:value\n column \u2013 \nStackedVector\n   This is provides a view of the original columns stacked together.\n\n\nId columns \u2013 \nRepeatedVector\n   This repeats the original columns N times where N is the number of columns stacked.\n\n\nFor more details on the storage representation, see:\n\n\ndump\n(\nstackdf\n(\niris\n))\n\n\n\n\n\n\nNone of these reshaping functions perform any aggregation. To do aggregation, use the split-apply-combine functions in combination with reshaping. Here is an example:\n\n\nd\n \n=\n \nstack\n(\niris\n)\n\n\nx\n \n=\n \nby\n(\nd\n,\n \n[\n:\nvariable\n,\n \n:\nSpecies\n],\n \ndf\n \n-\n \nDataFrame\n(\nvsum\n \n=\n \nmean\n(\ndf\n[\n:\nvalue\n])))\n\n\nunstack\n(\nx\n,\n \n:\nSpecies\n,\n \n:\nvsum\n)", 
            "title": "Reshaping"
        }, 
        {
            "location": "/man/reshaping_and_pivoting/#reshaping-and-pivoting-data", 
            "text": "Reshape data from wide to long format using the  stack  function:  using   DataFrames ,   RDatasets  iris   =   dataset ( datasets ,   iris )  iris [ : id ]   =   1 : size ( iris ,   1 )    # this makes it easier to unstack  d   =   stack ( iris ,   1 : 4 )   The second optional argument to  stack  indicates the columns to be stacked. These are normally referred to as the measured variables. Column names can also be given:  d   =   stack ( iris ,   [ : SepalLength ,   : SepalWidth ,   : PetalLength ,   : PetalWidth ])   Note that all columns can be of different types. Type promotion follows the rules of  vcat .  The stacked DataFrame that results includes all of the columns not specified to be stacked. These are repeated for each stacked column. These are normally refered to as identifier (id) columns. In addition to the id columns, two additional columns labeled  :variable  and  :values  contain the column identifier and the stacked columns.  A third optional argument to  stack  represents the id columns that are repeated. This makes it easier to specify which variables you want included in the long format:  d   =   stack ( iris ,   [ : SepalLength ,   : SepalWidth ],   : Species )   melt  is an alternative function to reshape from wide to long format. It is based on  stack , but it prefers specification of the id columns as:  d   =   melt ( iris ,   : Species )   All other columns are assumed to be measured variables (they are stacked).  You can also stack an entire DataFrame. The default stacks all floating-point columns:  d   =   stack ( iris )   unstack  converts from a long format to a wide format. The default is requires specifying which columns are an id variable, column variable names, and column values:  longdf   =   melt ( iris ,   [ : Species ,   : id ])  widedf   =   unstack ( longdf ,   : id ,   : variable ,   : value )   If the remaining columns are unique, you can skip the id variable and use:  widedf   =   unstack ( longdf ,   : variable ,   : value )   stackdf  and  meltdf  are two additional functions that work like  stack  and  melt , but they provide a view into the original wide DataFrame. Here is an example:  d   =   stackdf ( iris )   This saves memory. To create the view, several AbstractVectors are defined:  :variable  column \u2013  EachRepeatedVector    This repeats the variables N times where N is the number of rows of the original AbstractDataFrame.  :value  column \u2013  StackedVector    This is provides a view of the original columns stacked together.  Id columns \u2013  RepeatedVector    This repeats the original columns N times where N is the number of columns stacked.  For more details on the storage representation, see:  dump ( stackdf ( iris ))   None of these reshaping functions perform any aggregation. To do aggregation, use the split-apply-combine functions in combination with reshaping. Here is an example:  d   =   stack ( iris )  x   =   by ( d ,   [ : variable ,   : Species ],   df   -   DataFrame ( vsum   =   mean ( df [ : value ])))  unstack ( x ,   : Species ,   : vsum )", 
            "title": "Reshaping and Pivoting Data"
        }, 
        {
            "location": "/man/sorting/", 
            "text": "Sorting\n\n\nSorting is a fundamental component of data analysis. Basic sorting is trivial: just calling \nsort!\n will sort all columns, in place:\n\n\nusing\n \nDataFrames\n,\n \nRDatasets\n\n\n\niris\n \n=\n \ndataset\n(\ndatasets\n,\n \niris\n)\n\n\nsort!\n(\niris\n)\n\n\n\n\n\n\nIn Sorting DataFrames, you may want to sort different columns with different options. Here are some examples showing most of the possible options:\n\n\nsort!\n(\niris\n,\n \nrev\n \n=\n \ntrue\n)\n\n\nsort!\n(\niris\n,\n \ncols\n \n=\n \n[\n:\nSepalWidth\n,\n \n:\nSepalLength\n])\n\n\n\nsort!\n(\niris\n,\n \ncols\n \n=\n \n[\norder\n(\n:\nSpecies\n,\n \nby\n \n=\n \nuppercase\n),\n\n                    \norder\n(\n:\nSepalLength\n,\n \nrev\n \n=\n \ntrue\n)])\n\n\n\n\n\n\nKeywords used above include \ncols\n (to specify columns), \nrev\n (to sort a column or the whole DataFrame in reverse), and \nby\n (to apply a function to a column/DataFrame). Each keyword can either be a single value, or can be a tuple or array, with values corresponding to individual columns.\n\n\nAs an alternative to using array or tuple values, \norder\n to specify an ordering for a particular column within a set of columns\n\n\nThe following two examples show two ways to sort the \niris\n dataset with the same result: \nSpecies\n will be ordered in reverse lexicographic order, and within species, rows will be sorted by increasing sepal length and width:\n\n\nsort!\n(\niris\n,\n \ncols\n \n=\n \n(\n:\nSpecies\n,\n \n:\nSepalLength\n,\n \n:\nSepalWidth\n),\n\n      \nrev\n \n=\n \n(\ntrue\n,\n \nfalse\n,\n \nfalse\n))\n\n\n\nsort!\n(\niris\n,\n \ncols\n \n=\n \n(\norder\n(\n:\nSpecies\n,\n \nrev\n \n=\n \ntrue\n),\n \n:\nSepalLength\n,\n \n:\nSepalWidth\n))", 
            "title": "Sorting"
        }, 
        {
            "location": "/man/sorting/#sorting", 
            "text": "Sorting is a fundamental component of data analysis. Basic sorting is trivial: just calling  sort!  will sort all columns, in place:  using   DataFrames ,   RDatasets  iris   =   dataset ( datasets ,   iris )  sort! ( iris )   In Sorting DataFrames, you may want to sort different columns with different options. Here are some examples showing most of the possible options:  sort! ( iris ,   rev   =   true )  sort! ( iris ,   cols   =   [ : SepalWidth ,   : SepalLength ])  sort! ( iris ,   cols   =   [ order ( : Species ,   by   =   uppercase ), \n                     order ( : SepalLength ,   rev   =   true )])   Keywords used above include  cols  (to specify columns),  rev  (to sort a column or the whole DataFrame in reverse), and  by  (to apply a function to a column/DataFrame). Each keyword can either be a single value, or can be a tuple or array, with values corresponding to individual columns.  As an alternative to using array or tuple values,  order  to specify an ordering for a particular column within a set of columns  The following two examples show two ways to sort the  iris  dataset with the same result:  Species  will be ordered in reverse lexicographic order, and within species, rows will be sorted by increasing sepal length and width:  sort! ( iris ,   cols   =   ( : Species ,   : SepalLength ,   : SepalWidth ), \n       rev   =   ( true ,   false ,   false ))  sort! ( iris ,   cols   =   ( order ( : Species ,   rev   =   true ),   : SepalLength ,   : SepalWidth ))", 
            "title": "Sorting"
        }, 
        {
            "location": "/man/formulas/", 
            "text": "The Formula, ModelFrame and ModelMatrix Types\n\n\nIn regression analysis, we often want to describe the relationship between a response variable and one or more input variables in terms of main effects and interactions. To facilitate the specification of a regression model in terms of the columns of a \nDataFrame\n, the DataFrames package provides a \nFormula\n type, which is created using the \n@formula\n macro in Julia:\n\n\nfm\n \n=\n \n@formula\n(\nZ\n \n~\n \nX\n \n+\n \nY\n)\n\n\n\n\n\n\nA \nFormula\n object can be used to transform a \nDataFrame\n into a \nModelFrame\n object:\n\n\ndf\n \n=\n \nDataFrame\n(\nX\n \n=\n \nrandn\n(\n10\n),\n \nY\n \n=\n \nrandn\n(\n10\n),\n \nZ\n \n=\n \nrandn\n(\n10\n))\n\n\nmf\n \n=\n \nModelFrame\n(\n@formula\n(\nZ\n \n~\n \nX\n \n+\n \nY\n),\n \ndf\n)\n\n\n\n\n\n\nA \nModelFrame\n object is just a simple wrapper around a \nDataFrame\n. For modeling purposes, one generally wants to construct a \nModelMatrix\n, which constructs a \nMatrix{Float64}\n that can be used directly to fit a statistical model:\n\n\nmm\n \n=\n \nModelMatrix\n(\nModelFrame\n(\n@formula\n(\nZ\n \n~\n \nX\n \n+\n \nY\n),\n \ndf\n))\n\n\n\n\n\n\nNote that \nmm\n contains an additional column consisting entirely of \n1.0\n values. This is used to fit an intercept term in a regression model.\n\n\nIn addition to specifying main effects, it is possible to specify interactions using the \n operator inside a \nFormula\n:\n\n\nmm\n \n=\n \nModelMatrix\n(\nModelFrame\n(\n@formula\n(\nZ\n \n~\n \nX\n \n+\n \nY\n \n+\n \nX\nY\n),\n \ndf\n))\n\n\n\n\n\n\nIf you would like to specify both main effects and an interaction term at once, use the \n*\n operator inside a \nFormula\n:\n\n\nmm\n \n=\n \nModelMatrix\n(\nModelFrame\n(\n@formula\n(\nZ\n \n~\n \nX\n*\nY\n),\n \ndf\n))\n\n\n\n\n\n\nYou can control how categorical variables (e.g., \nPooledDataArray\n columns) are converted to \nModelMatrix\n columns by specifying \ncontrasts\n when you construct a \nModelFrame\n:\n\n\nmm\n \n=\n \nModelMatrix\n(\nModelFrame\n(\n@formula\n(\nZ\n \n~\n \nX\n*\nY\n),\n \ndf\n,\n \ncontrasts\n \n=\n \nDict\n(\n:\nX\n \n=\n \nHelmertCoding\n())))\n\n\n\n\n\n\nContrasts can also be modified in an existing \nModelFrame\n:\n\n\nmf\n \n=\n \nModelFrame\n(\n@formula\n(\nZ\n \n~\n \nX\n*\nY\n),\n \ndf\n)\n\n\ncontrasts!\n(\nmf\n,\n \nX\n \n=\n \nHelmertCoding\n())\n\n\n\n\n\n\nThe construction of model matrices makes it easy to formulate complex statistical models. These are used to good effect by the \nGLM Package.", 
            "title": "Formulas"
        }, 
        {
            "location": "/man/formulas/#the-formula-modelframe-and-modelmatrix-types", 
            "text": "In regression analysis, we often want to describe the relationship between a response variable and one or more input variables in terms of main effects and interactions. To facilitate the specification of a regression model in terms of the columns of a  DataFrame , the DataFrames package provides a  Formula  type, which is created using the  @formula  macro in Julia:  fm   =   @formula ( Z   ~   X   +   Y )   A  Formula  object can be used to transform a  DataFrame  into a  ModelFrame  object:  df   =   DataFrame ( X   =   randn ( 10 ),   Y   =   randn ( 10 ),   Z   =   randn ( 10 ))  mf   =   ModelFrame ( @formula ( Z   ~   X   +   Y ),   df )   A  ModelFrame  object is just a simple wrapper around a  DataFrame . For modeling purposes, one generally wants to construct a  ModelMatrix , which constructs a  Matrix{Float64}  that can be used directly to fit a statistical model:  mm   =   ModelMatrix ( ModelFrame ( @formula ( Z   ~   X   +   Y ),   df ))   Note that  mm  contains an additional column consisting entirely of  1.0  values. This is used to fit an intercept term in a regression model.  In addition to specifying main effects, it is possible to specify interactions using the   operator inside a  Formula :  mm   =   ModelMatrix ( ModelFrame ( @formula ( Z   ~   X   +   Y   +   X Y ),   df ))   If you would like to specify both main effects and an interaction term at once, use the  *  operator inside a  Formula :  mm   =   ModelMatrix ( ModelFrame ( @formula ( Z   ~   X * Y ),   df ))   You can control how categorical variables (e.g.,  PooledDataArray  columns) are converted to  ModelMatrix  columns by specifying  contrasts  when you construct a  ModelFrame :  mm   =   ModelMatrix ( ModelFrame ( @formula ( Z   ~   X * Y ),   df ,   contrasts   =   Dict ( : X   =   HelmertCoding ())))   Contrasts can also be modified in an existing  ModelFrame :  mf   =   ModelFrame ( @formula ( Z   ~   X * Y ),   df )  contrasts! ( mf ,   X   =   HelmertCoding ())   The construction of model matrices makes it easy to formulate complex statistical models. These are used to good effect by the  GLM Package.", 
            "title": "The Formula, ModelFrame and ModelMatrix Types"
        }, 
        {
            "location": "/man/pooling/", 
            "text": "Pooling Data (Representing Factors)\n\n\nOften, we have to deal with factors that take on a small number of levels:\n\n\ndv\n \n=\n \n@data\n([\nGroup A\n,\n \nGroup A\n,\n \nGroup A\n,\n\n            \nGroup B\n,\n \nGroup B\n,\n \nGroup B\n])\n\n\n\n\n\n\nThe naive encoding used in a \nDataArray\n represents every entry of this vector as a full string. In contrast, we can represent the data more efficiently by replacing the strings with indices into a small pool of levels. This is what the \nPooledDataArray\n does:\n\n\npdv\n \n=\n \n@pdata\n([\nGroup A\n,\n \nGroup A\n,\n \nGroup A\n,\n\n              \nGroup B\n,\n \nGroup B\n,\n \nGroup B\n])\n\n\n\n\n\n\nIn addition to representing repeated data efficiently, the \nPooledDataArray\n allows us to determine the levels of the factor at any time using the \nlevels\n function:\n\n\nlevels\n(\npdv\n)\n\n\n\n\n\n\nBy default, a \nPooledDataArray\n is able to represent 2\n32\ndifferents levels. You can use less memory by calling the \ncompact\n function:\n\n\npdv\n \n=\n \ncompact\n(\npdv\n)\n\n\n\n\n\n\nOften, you will have factors encoded inside a DataFrame with \nDataArray\n columns instead of \nPooledDataArray\n columns. You can do conversion of a single column using the \npool\n function:\n\n\npdv\n \n=\n \npool\n(\ndv\n)\n\n\n\n\n\n\nOr you can edit the columns of a \nDataFrame\n in-place using the \npool!\n function:\n\n\ndf\n \n=\n \nDataFrame\n(\nA\n \n=\n \n[\n1\n,\n \n1\n,\n \n1\n,\n \n2\n,\n \n2\n,\n \n2\n],\n\n               \nB\n \n=\n \n[\nX\n,\n \nX\n,\n \nX\n,\n \nY\n,\n \nY\n,\n \nY\n])\n\n\npool!\n(\ndf\n,\n \n[\n:\nA\n,\n \n:\nB\n])\n\n\n\n\n\n\nPooling columns is important for working with the \nGLM package\n When fitting regression models, \nPooledDataArray\n columns in the input are translated into 0/1 indicator columns in the \nModelMatrix\n with one column for each of the levels of the \nPooledDataArray\n. This allows one to analyze categorical data efficiently.", 
            "title": "Pooling"
        }, 
        {
            "location": "/man/pooling/#pooling-data-representing-factors", 
            "text": "Often, we have to deal with factors that take on a small number of levels:  dv   =   @data ([ Group A ,   Group A ,   Group A , \n             Group B ,   Group B ,   Group B ])   The naive encoding used in a  DataArray  represents every entry of this vector as a full string. In contrast, we can represent the data more efficiently by replacing the strings with indices into a small pool of levels. This is what the  PooledDataArray  does:  pdv   =   @pdata ([ Group A ,   Group A ,   Group A , \n               Group B ,   Group B ,   Group B ])   In addition to representing repeated data efficiently, the  PooledDataArray  allows us to determine the levels of the factor at any time using the  levels  function:  levels ( pdv )   By default, a  PooledDataArray  is able to represent 2 32 differents levels. You can use less memory by calling the  compact  function:  pdv   =   compact ( pdv )   Often, you will have factors encoded inside a DataFrame with  DataArray  columns instead of  PooledDataArray  columns. You can do conversion of a single column using the  pool  function:  pdv   =   pool ( dv )   Or you can edit the columns of a  DataFrame  in-place using the  pool!  function:  df   =   DataFrame ( A   =   [ 1 ,   1 ,   1 ,   2 ,   2 ,   2 ], \n                B   =   [ X ,   X ,   X ,   Y ,   Y ,   Y ])  pool! ( df ,   [ : A ,   : B ])   Pooling columns is important for working with the  GLM package  When fitting regression models,  PooledDataArray  columns in the input are translated into 0/1 indicator columns in the  ModelMatrix  with one column for each of the levels of the  PooledDataArray . This allows one to analyze categorical data efficiently.", 
            "title": "Pooling Data (Representing Factors)"
        }, 
        {
            "location": "/man/querying_frameworks/", 
            "text": "Querying frameworks\n\n\n\n\nQuery.jl\n\n\nThe \nQuery.jl\n package provides advanced data manipulation capabilities for \nDataFrames\n (and many other data structures). This section provides a short introduction to the package, the \nQuery.jl documentation\n has a more comprehensive documentation of the package.\n\n\nTo get started, install the Query.jl package:\n\n\nPkg\n.\nadd\n(\nQuery\n)\n\n\n\n\n\n\nA query is started with the \n@from\n macro and consists of a series of query commands. Query.jl provides commands that can filter, project, join, group, flatten and group data from a \nDataFrame\n. A query can return an iterator, or one can materialize the results of a query into a variety of data structures, including a new \nDataFrame\n.\n\n\nA simple example of a query looks like this:\n\n\n```@example 1\nusing DataFrames, Query\n\n\ndf = DataFrame(name=[\"John\", \"Sally\", \"Roger\"], age=[54., 34., 79.], children=[0, 2, 4])\n\n\nq1 = @from i in df begin\n     @where i.age \n 40\n     @select {number_of_children=i.children, i.name}\n     @collect DataFrame\nend\n\n\nThe\n \nquery\n \nstarts\n \nwith\n \nthe\n \n`\n@\nfrom\n`\n \nmacro\n.\n \nThe\n \nfirst\n \nargument\n \n`\ni\n`\n \nis\n \nthe\n \nname\n \nof\n \nthe\n \nrange\n \nvariable\n \nthat\n \nwill\n \nbe\n \nused\n \nto\n \nrefer\n \nto\n \nan\n \nindividual\n \nrow\n \nin\n \nlater\n \nquery\n \ncommands\n.\n \nThe\n \nnext\n \nargument\n \n`\ndf\n`\n \nis\n \nthe\n \ndata\n \nsource\n \nthat\n \none\n \nwants\n \nto\n \nquery\n.\n \nThe\n \n`\n@\nwhere\n`\n \ncommand\n \nin\n \nthis\n \nquery\n \nwill\n \nfilter\n \nthe\n \nsource\n \ndata\n \nby\n \napplying\n \nthe\n \nfilter\n \ncondition\n \n`\ni\n.\nage\n \n \n40\n`\n.\n \nThis\n \nfilters\n \nout\n \nany\n \nrows\n \nin\n \nwhich\n \nthe\n \n`\nage\n`\n \ncolumn\n \nis\n \nnot\n \nlarger\n \nthan\n \n40\n.\n \nThe\n \n`\n@\nselect\n`\n \ncommand\n \nthen\n \nprojects\n \nthe\n \ncolumns\n \nof\n \nthe\n \nsource\n \ndata\n \nonto\n \na\n \nnew\n \ncolumn\n \nstructure\n.\n \nThe\n \nexample\n \nhere\n \napplies\n \nthree\n \nspecific\n \nmodifications\n:\n \n1\n)\n \nit\n \nonly\n \nkeeps\n \na\n \nsubset\n \nof\n \nthe\n \ncolumns\n \nin\n \nthe\n \nsource\n \n`\nDataFrame\n`\n,\n \ni\n.\ne\n.\n \nthe\n \n`\nage\n`\n \ncolumn\n \nwill\n \nnot\n \nbe\n \npart\n \nof\n \nthe\n \ntransformed\n \ndata\n;\n \n2\n)\n \nit\n \nchanges\n \nthe\n \norder\n \nof\n \nthe\n \ntwo\n \ncolumns\n \nthat\n \nare\n \nselected\n;\n \nand\n \n3\n)\n \nit\n \nrenames\n \none\n \nof\n \nthe\n \ncolumns\n \nthat\n \nis\n \nselected\n \nfrom\n \n`\nchildren\n`\n \nto\n \n`\nnumber_of_children\n`\n.\n \nThe\n \nexample\n \nquery\n \nuses\n \nthe\n \n`\n{}\n`\n \nsyntax\n \nto\n \nachieve\n \nthis\n.\n \nA\n \n`\n{}\n`\n \nin\n \na\n \nQuery\n.\njl\n \nexpression\n \ninstantiates\n \na\n \nnew\n \n[\nNamedTuple\n]\n(\nhttps\n://\ngithub\n.\ncom\n/\nblackrock\n/\nNamedTuples\n.\njl\n),\n \ni\n.\ne\n.\n \nit\n \nis\n \na\n \nshortcut\n \nfor\n \nwriting\n \n`\n@\nNT\n(\nnumber_of_children\n=\ni\n.\nchildren\n,\n \nname\n=\ni\n.\nname\n)\n`\n.\n \nThe\n \n`\n@\ncollect\n`\n \nstatement\n \ndetermines\n \nthe\n \ndata\n \nstructure\n \nthat\n \nthe\n \nquery\n \nreturns\n.\n \nIn\n \nthis\n \nexample\n \nthe\n \nresults\n \nare\n \nreturned\n \nas\n \na\n \n`\nDataFrame\n`\n.\n\n\n\n\nA\n \nquery\n \nwithout\n \na\n \n`\n@\ncollect\n`\n \nstatement\n \nreturns\n \na\n \nstandard\n \njulia\n \niterator\n \nthat\n \ncan\n \nbe\n \nused\n \nwith\n \nany\n \nnormal\n \njulia\n \nlanguage\n \nconstruct\n \nthat\n \ncan\n \ndeal\n \nwith\n \niterators\n.\n \nThe\n \nfollowing\n \ncode\n \nreturns\n \na\n \njulia\n \niterator\n \nfor\n \nthe\n \nquery\n \nresults\n:\n\n\n\n\n```\n@\nexample\n \n1\n\n\nq2\n \n=\n \n@\nfrom\n \ni\n \nin\n \ndf\n \nbegin\n\n     \n@\nwhere\n \ni\n.\nage\n \n \n40\n\n     \n@\nselect\n \n{\nnumber_of_children\n=\ni\n.\nchildren\n,\n \ni\n.\nname\n}\n\n\nend\n\n\nnothing\n \n#\n \nhide\n\n\n\n\n\n\nOne can loop over the results using a standard julia \nfor\n statement:\n\n\n```@example 1\ntotal_children = 0\nfor i in q2\n    total_children += i.number_of_children\nend\n\n\nprintln(\"Total number of children: $(get(total_children))\")\n\n\nOr one can use a comprehension to extract the name of a subset of rows:\n\n\n```@example 1\ny = [i.name for i in q2 if i.number_of_children \n 0]\n\n\n\n\n\nThe last example (extracting only the name and applying a second filter) could of course be completely expressed as a query expression:\n\n\n@example 1\nq3 = @from i in df begin\n     @where i.age \n 40 \n i.children \n 0\n     @select i.name\n     @collect\nend\n\n\nA query that ends with a \n@collect\n statement without a specific type will materialize the query results into an array. Note also the difference in the \n@select\n statement: The previous queries all used the \n{}\n syntax in the \n@select\n statement to project results into a tabular format. The last query instead just selects a single value from each row in the \n@select\n statement.\n\n\nThese examples only scratch the surface of what one can do with \nQuery.jl\n, and the interested reader is referred to the \nQuery.jl documentation\n for more information.", 
            "title": "Querying frameworks"
        }, 
        {
            "location": "/man/querying_frameworks/#querying-frameworks", 
            "text": "", 
            "title": "Querying frameworks"
        }, 
        {
            "location": "/man/querying_frameworks/#queryjl", 
            "text": "The  Query.jl  package provides advanced data manipulation capabilities for  DataFrames  (and many other data structures). This section provides a short introduction to the package, the  Query.jl documentation  has a more comprehensive documentation of the package.  To get started, install the Query.jl package:  Pkg . add ( Query )   A query is started with the  @from  macro and consists of a series of query commands. Query.jl provides commands that can filter, project, join, group, flatten and group data from a  DataFrame . A query can return an iterator, or one can materialize the results of a query into a variety of data structures, including a new  DataFrame .  A simple example of a query looks like this:  ```@example 1\nusing DataFrames, Query  df = DataFrame(name=[\"John\", \"Sally\", \"Roger\"], age=[54., 34., 79.], children=[0, 2, 4])  q1 = @from i in df begin\n     @where i.age   40\n     @select {number_of_children=i.children, i.name}\n     @collect DataFrame\nend  The   query   starts   with   the   ` @ from `   macro .   The   first   argument   ` i `   is   the   name   of   the   range   variable   that   will   be   used   to   refer   to   an   individual   row   in   later   query   commands .   The   next   argument   ` df `   is   the   data   source   that   one   wants   to   query .   The   ` @ where `   command   in   this   query   will   filter   the   source   data   by   applying   the   filter   condition   ` i . age     40 ` .   This   filters   out   any   rows   in   which   the   ` age `   column   is   not   larger   than   40 .   The   ` @ select `   command   then   projects   the   columns   of   the   source   data   onto   a   new   column   structure .   The   example   here   applies   three   specific   modifications :   1 )   it   only   keeps   a   subset   of   the   columns   in   the   source   ` DataFrame ` ,   i . e .   the   ` age `   column   will   not   be   part   of   the   transformed   data ;   2 )   it   changes   the   order   of   the   two   columns   that   are   selected ;   and   3 )   it   renames   one   of   the   columns   that   is   selected   from   ` children `   to   ` number_of_children ` .   The   example   query   uses   the   ` {} `   syntax   to   achieve   this .   A   ` {} `   in   a   Query . jl   expression   instantiates   a   new   [ NamedTuple ] ( https :// github . com / blackrock / NamedTuples . jl ),   i . e .   it   is   a   shortcut   for   writing   ` @ NT ( number_of_children = i . children ,   name = i . name ) ` .   The   ` @ collect `   statement   determines   the   data   structure   that   the   query   returns .   In   this   example   the   results   are   returned   as   a   ` DataFrame ` .  A   query   without   a   ` @ collect `   statement   returns   a   standard   julia   iterator   that   can   be   used   with   any   normal   julia   language   construct   that   can   deal   with   iterators .   The   following   code   returns   a   julia   iterator   for   the   query   results :  ``` @ example   1  q2   =   @ from   i   in   df   begin \n      @ where   i . age     40 \n      @ select   { number_of_children = i . children ,   i . name }  end  nothing   #   hide   One can loop over the results using a standard julia  for  statement:  ```@example 1\ntotal_children = 0\nfor i in q2\n    total_children += i.number_of_children\nend  println(\"Total number of children: $(get(total_children))\")  Or one can use a comprehension to extract the name of a subset of rows:\n\n\n```@example 1\ny = [i.name for i in q2 if i.number_of_children   0]  The last example (extracting only the name and applying a second filter) could of course be completely expressed as a query expression:  @example 1\nq3 = @from i in df begin\n     @where i.age   40   i.children   0\n     @select i.name\n     @collect\nend  A query that ends with a  @collect  statement without a specific type will materialize the query results into an array. Note also the difference in the  @select  statement: The previous queries all used the  {}  syntax in the  @select  statement to project results into a tabular format. The last query instead just selects a single value from each row in the  @select  statement.  These examples only scratch the surface of what one can do with  Query.jl , and the interested reader is referred to the  Query.jl documentation  for more information.", 
            "title": "Query.jl"
        }, 
        {
            "location": "/lib/maintypes/", 
            "text": "Main Types\n\n\n\n\nDataFrames.AbstractDataFrame\n\n\nDataFrames.DataFrame\n\n\nDataFrames.SubDataFrame\n\n\n\n\n...\n\n\n#\n\n\nDataFrames.AbstractDataFrame\n \n \nType\n.\n\n\nAn abstract type for which all concrete types expose a database-like interface.\n\n\nCommon methods\n\n\nAn AbstractDataFrame is a two-dimensional table with Symbols for column names. An AbstractDataFrame is also similar to an Associative type in that it allows indexing by a key (the columns).\n\n\nThe following are normally implemented for AbstractDataFrames:\n\n\n\n\ndescribe\n : summarize columns\n\n\ndump\n : show structure\n\n\nhcat\n : horizontal concatenation\n\n\nvcat\n : vertical concatenation\n\n\nnames\n : columns names\n\n\nnames!\n : set columns names\n\n\nrename!\n : rename columns names based on keyword arguments\n\n\neltypes\n : \neltype\n of each column\n\n\nlength\n : number of columns\n\n\nsize\n : (nrows, ncols)\n\n\nhead\n : first \nn\n rows\n\n\ntail\n : last \nn\n rows\n\n\nconvert\n : convert to an array\n\n\nDataArray\n : convert to a DataArray\n\n\ncompletecases\n : indexes of complete cases (rows with no NA's)\n\n\ncompletecases!\n : remove rows with NA's\n\n\nnonunique\n : indexes of duplicate rows\n\n\nunique!\n : remove duplicate rows\n\n\nsimilar\n : a DataFrame with similar columns as \nd\n\n\n\n\nIndexing\n\n\nTable columns are accessed (\ngetindex\n) by a single index that can be a symbol identifier, an integer, or a vector of each. If a single column is selected, just the column object is returned. If multiple columns are selected, some AbstractDataFrame is returned.\n\n\nd\n[\n:\ncolA\n]\n\n\nd\n[\n3\n]\n\n\nd\n[[\n:\ncolA\n,\n \n:\ncolB\n]]\n\n\nd\n[[\n1\n:\n3\n;\n \n5\n]]\n\n\n\n\n\n\nRows and columns can be indexed like a \nMatrix\n with the added feature of indexing columns by name.\n\n\nd\n[\n1\n:\n3\n,\n \n:\ncolA\n]\n\n\nd\n[\n3\n,\n3\n]\n\n\nd\n[\n3\n,\n:\n]\n\n\nd\n[\n3\n,[\n:\ncolA\n,\n \n:\ncolB\n]]\n\n\nd\n[\n:\n,\n \n[\n:\ncolA\n,\n \n:\ncolB\n]]\n\n\nd\n[[\n1\n:\n3\n;\n \n5\n],\n \n:\n]\n\n\n\n\n\n\nsetindex\n works similarly.\n\n\nsource\n\n\n#\n\n\nDataFrames.DataFrame\n \n \nType\n.\n\n\nAn AbstractDataFrame that stores a set of named columns\n\n\nThe columns are normally AbstractVectors stored in memory, particularly a Vector, DataVector, or PooledDataVector.\n\n\nConstructors\n\n\nDataFrame\n(\ncolumns\n::\nVector\n,\n \nnames\n::\nVector\n{\nSymbol\n})\n\n\nDataFrame\n(\nkwargs\n...\n)\n\n\nDataFrame\n()\n \n# an empty DataFrame\n\n\nDataFrame\n(\nt\n::\nType\n,\n \nnrows\n::\nInteger\n,\n \nncols\n::\nInteger\n)\n \n# an empty DataFrame of arbitrary size\n\n\nDataFrame\n(\ncolumn_eltypes\n::\nVector\n,\n \nnames\n::\nVector\n,\n \nnrows\n::\nInteger\n)\n\n\nDataFrame\n(\nds\n::\nVector\n{\nAssociative\n})\n\n\n\n\n\n\nArguments\n\n\n\n\ncolumns\n : a Vector with each column as contents\n\n\nnames\n : the column names\n\n\nkwargs\n : the key gives the column names, and the value is the column contents\n\n\nt\n : elemental type of all columns\n\n\nnrows\n, \nncols\n : number of rows and columns\n\n\ncolumn_eltypes\n : elemental type of each column\n\n\nds\n : a vector of Associatives\n\n\n\n\nEach column in \ncolumns\n should be the same length.\n\n\nNotes\n\n\nMost of the default constructors convert columns to \nDataArrays\n.  The base constructor, \nDataFrame(columns::Vector, names::Vector{Symbol})\n does not convert to \nDataArrays\n.\n\n\nA \nDataFrame\n is a lightweight object. As long as columns are not manipulated, creation of a DataFrame from existing AbstractVectors is inexpensive. For example, indexing on columns is inexpensive, but indexing by rows is expensive because copies are made of each column.\n\n\nBecause column types can vary, a DataFrame is not type stable. For performance-critical code, do not index into a DataFrame inside of loops.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n()\n\n\nv\n \n=\n \n[\nx\n,\ny\n,\nz\n][\nrand\n(\n1\n:\n3\n,\n \n10\n)]\n\n\ndf1\n \n=\n \nDataFrame\n(\nAny\n[[\n1\n:\n10\n],\n \nv\n,\n \nrand\n(\n10\n)],\n \n[\n:\nA\n,\n \n:\nB\n,\n \n:\nC\n])\n  \n# columns are Arrays\n\n\ndf2\n \n=\n \nDataFrame\n(\nA\n \n=\n \n1\n:\n10\n,\n \nB\n \n=\n \nv\n,\n \nC\n \n=\n \nrand\n(\n10\n))\n           \n# columns are DataArrays\n\n\ndump\n(\ndf1\n)\n\n\ndump\n(\ndf2\n)\n\n\ndescribe\n(\ndf2\n)\n\n\nhead\n(\ndf1\n)\n\n\ndf1\n[\n:\nA\n]\n \n+\n \ndf2\n[\n:\nC\n]\n\n\ndf1\n[\n1\n:\n4\n,\n \n1\n:\n2\n]\n\n\ndf1\n[[\n:\nA\n,\n:\nC\n]]\n\n\ndf1\n[\n1\n:\n2\n,\n \n[\n:\nA\n,\n:\nC\n]]\n\n\ndf1\n[\n:\n,\n \n[\n:\nA\n,\n:\nC\n]]\n\n\ndf1\n[\n:\n,\n \n[\n1\n,\n3\n]]\n\n\ndf1\n[\n1\n:\n4\n,\n \n:\n]\n\n\ndf1\n[\n1\n:\n4\n,\n \n:\nC\n]\n\n\ndf1\n[\n1\n:\n4\n,\n \n:\nC\n]\n \n=\n \n40.\n \n*\n \ndf1\n[\n1\n:\n4\n,\n \n:\nC\n]\n\n\n[\ndf1\n;\n \ndf2\n]\n  \n# vcat\n\n\n[\ndf1\n  \ndf2\n]\n  \n# hcat\n\n\nsize\n(\ndf1\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.SubDataFrame\n \n \nType\n.\n\n\nA view of row subsets of an AbstractDataFrame\n\n\nA \nSubDataFrame\n is meant to be constructed with \nview\n.  A SubDataFrame is used frequently in split/apply sorts of operations.\n\n\nview\n(\nd\n::\nAbstractDataFrame\n,\n \nrows\n)\n\n\n\n\n\n\nArguments\n\n\n\n\nd\n : an AbstractDataFrame\n\n\nrows\n : any indexing type for rows, typically an Int, AbstractVector{Int}, AbstractVector{Bool}, or a Range\n\n\n\n\nNotes\n\n\nA \nSubDataFrame\n is an AbstractDataFrame, so expect that most DataFrame functions should work. Such methods include \ndescribe\n, \ndump\n, \nnrow\n, \nsize\n, \nby\n, \nstack\n, and \njoin\n. Indexing is just like a DataFrame; copies are returned.\n\n\nTo subset along columns, use standard column indexing as that creates a view to the columns by default. To subset along rows and columns, use column-based indexing with \nview\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\na\n \n=\n \nrepeat\n([\n1\n,\n \n2\n,\n \n3\n,\n \n4\n],\n \nouter\n=\n[\n2\n]),\n\n               \nb\n \n=\n \nrepeat\n([\n2\n,\n \n1\n],\n \nouter\n=\n[\n4\n]),\n\n               \nc\n \n=\n \nrandn\n(\n8\n))\n\n\nsdf1\n \n=\n \nview\n(\ndf\n,\n \n1\n:\n6\n)\n\n\nsdf2\n \n=\n \nview\n(\ndf\n,\n \ndf\n[\n:\na\n]\n \n.\n \n1\n)\n\n\nsdf3\n \n=\n \nview\n(\ndf\n[[\n1\n,\n3\n]],\n \ndf\n[\n:\na\n]\n \n.\n \n1\n)\n  \n# row and column subsetting\n\n\nsdf4\n \n=\n \ngroupby\n(\ndf\n,\n \n:\na\n)[\n1\n]\n  \n# indexing a GroupedDataFrame returns a SubDataFrame\n\n\nsdf5\n \n=\n \nview\n(\nsdf1\n,\n \n1\n:\n3\n)\n\n\nsdf1\n[\n:\n,[\n:\na\n,\n:\nb\n]]\n\n\n\n\n\n\nsource", 
            "title": "Main types"
        }, 
        {
            "location": "/lib/maintypes/#main-types", 
            "text": "DataFrames.AbstractDataFrame  DataFrames.DataFrame  DataFrames.SubDataFrame   ...  #  DataFrames.AbstractDataFrame     Type .  An abstract type for which all concrete types expose a database-like interface.  Common methods  An AbstractDataFrame is a two-dimensional table with Symbols for column names. An AbstractDataFrame is also similar to an Associative type in that it allows indexing by a key (the columns).  The following are normally implemented for AbstractDataFrames:   describe  : summarize columns  dump  : show structure  hcat  : horizontal concatenation  vcat  : vertical concatenation  names  : columns names  names!  : set columns names  rename!  : rename columns names based on keyword arguments  eltypes  :  eltype  of each column  length  : number of columns  size  : (nrows, ncols)  head  : first  n  rows  tail  : last  n  rows  convert  : convert to an array  DataArray  : convert to a DataArray  completecases  : indexes of complete cases (rows with no NA's)  completecases!  : remove rows with NA's  nonunique  : indexes of duplicate rows  unique!  : remove duplicate rows  similar  : a DataFrame with similar columns as  d   Indexing  Table columns are accessed ( getindex ) by a single index that can be a symbol identifier, an integer, or a vector of each. If a single column is selected, just the column object is returned. If multiple columns are selected, some AbstractDataFrame is returned.  d [ : colA ]  d [ 3 ]  d [[ : colA ,   : colB ]]  d [[ 1 : 3 ;   5 ]]   Rows and columns can be indexed like a  Matrix  with the added feature of indexing columns by name.  d [ 1 : 3 ,   : colA ]  d [ 3 , 3 ]  d [ 3 , : ]  d [ 3 ,[ : colA ,   : colB ]]  d [ : ,   [ : colA ,   : colB ]]  d [[ 1 : 3 ;   5 ],   : ]   setindex  works similarly.  source  #  DataFrames.DataFrame     Type .  An AbstractDataFrame that stores a set of named columns  The columns are normally AbstractVectors stored in memory, particularly a Vector, DataVector, or PooledDataVector.  Constructors  DataFrame ( columns :: Vector ,   names :: Vector { Symbol })  DataFrame ( kwargs ... )  DataFrame ()   # an empty DataFrame  DataFrame ( t :: Type ,   nrows :: Integer ,   ncols :: Integer )   # an empty DataFrame of arbitrary size  DataFrame ( column_eltypes :: Vector ,   names :: Vector ,   nrows :: Integer )  DataFrame ( ds :: Vector { Associative })   Arguments   columns  : a Vector with each column as contents  names  : the column names  kwargs  : the key gives the column names, and the value is the column contents  t  : elemental type of all columns  nrows ,  ncols  : number of rows and columns  column_eltypes  : elemental type of each column  ds  : a vector of Associatives   Each column in  columns  should be the same length.  Notes  Most of the default constructors convert columns to  DataArrays .  The base constructor,  DataFrame(columns::Vector, names::Vector{Symbol})  does not convert to  DataArrays .  A  DataFrame  is a lightweight object. As long as columns are not manipulated, creation of a DataFrame from existing AbstractVectors is inexpensive. For example, indexing on columns is inexpensive, but indexing by rows is expensive because copies are made of each column.  Because column types can vary, a DataFrame is not type stable. For performance-critical code, do not index into a DataFrame inside of loops.  Examples  df   =   DataFrame ()  v   =   [ x , y , z ][ rand ( 1 : 3 ,   10 )]  df1   =   DataFrame ( Any [[ 1 : 10 ],   v ,   rand ( 10 )],   [ : A ,   : B ,   : C ])    # columns are Arrays  df2   =   DataFrame ( A   =   1 : 10 ,   B   =   v ,   C   =   rand ( 10 ))             # columns are DataArrays  dump ( df1 )  dump ( df2 )  describe ( df2 )  head ( df1 )  df1 [ : A ]   +   df2 [ : C ]  df1 [ 1 : 4 ,   1 : 2 ]  df1 [[ : A , : C ]]  df1 [ 1 : 2 ,   [ : A , : C ]]  df1 [ : ,   [ : A , : C ]]  df1 [ : ,   [ 1 , 3 ]]  df1 [ 1 : 4 ,   : ]  df1 [ 1 : 4 ,   : C ]  df1 [ 1 : 4 ,   : C ]   =   40.   *   df1 [ 1 : 4 ,   : C ]  [ df1 ;   df2 ]    # vcat  [ df1    df2 ]    # hcat  size ( df1 )   source  #  DataFrames.SubDataFrame     Type .  A view of row subsets of an AbstractDataFrame  A  SubDataFrame  is meant to be constructed with  view .  A SubDataFrame is used frequently in split/apply sorts of operations.  view ( d :: AbstractDataFrame ,   rows )   Arguments   d  : an AbstractDataFrame  rows  : any indexing type for rows, typically an Int, AbstractVector{Int}, AbstractVector{Bool}, or a Range   Notes  A  SubDataFrame  is an AbstractDataFrame, so expect that most DataFrame functions should work. Such methods include  describe ,  dump ,  nrow ,  size ,  by ,  stack , and  join . Indexing is just like a DataFrame; copies are returned.  To subset along columns, use standard column indexing as that creates a view to the columns by default. To subset along rows and columns, use column-based indexing with  view .  Examples  df   =   DataFrame ( a   =   repeat ([ 1 ,   2 ,   3 ,   4 ],   outer = [ 2 ]), \n                b   =   repeat ([ 2 ,   1 ],   outer = [ 4 ]), \n                c   =   randn ( 8 ))  sdf1   =   view ( df ,   1 : 6 )  sdf2   =   view ( df ,   df [ : a ]   .   1 )  sdf3   =   view ( df [[ 1 , 3 ]],   df [ : a ]   .   1 )    # row and column subsetting  sdf4   =   groupby ( df ,   : a )[ 1 ]    # indexing a GroupedDataFrame returns a SubDataFrame  sdf5   =   view ( sdf1 ,   1 : 3 )  sdf1 [ : ,[ : a , : b ]]   source", 
            "title": "Main Types"
        }, 
        {
            "location": "/lib/utilities/", 
            "text": "Utilities\n\n\n\n\nBase.dump\n\n\nBase.unique\n\n\nDataFrames.completecases\n\n\nDataFrames.completecases!\n\n\nDataFrames.eltypes\n\n\nDataFrames.head\n\n\nDataFrames.names!\n\n\nDataFrames.nonunique\n\n\nDataFrames.rename\n\n\nDataFrames.rename!\n\n\nDataFrames.tail\n\n\nDataFrames.unique!\n\n\nStatsBase.describe\n\n\n\n\n...\n\n\n#\n\n\nDataFrames.eltypes\n \n \nFunction\n.\n\n\nColumn elemental types\n\n\neltypes\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\n\n\nResult\n\n\n\n\n::Vector{Type}\n : the elemental type of each column\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\neltypes\n(\ndf\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.head\n \n \nFunction\n.\n\n\nShow the first or last part of an AbstractDataFrame\n\n\nhead\n(\ndf\n::\nAbstractDataFrame\n,\n \nr\n::\nInt\n \n=\n \n6\n)\n\n\ntail\n(\ndf\n::\nAbstractDataFrame\n,\n \nr\n::\nInt\n \n=\n \n6\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nr\n : the number of rows to show\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the first or last part of \ndf\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nhead\n(\ndf\n)\n\n\ntail\n(\ndf\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.completecases\n \n \nFunction\n.\n\n\nIndexes of complete cases (rows without NA's)\n\n\ncompletecases\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\n\n\nResult\n\n\n\n\n::Vector{Bool}\n : indexes of complete cases\n\n\n\n\nSee also \ncompletecases!\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndf\n[[\n1\n,\n4\n,\n5\n],\n \n:\nx\n]\n \n=\n \nNA\n\n\ndf\n[[\n9\n,\n10\n],\n \n:\ny\n]\n \n=\n \nNA\n\n\ncompletecases\n(\ndf\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.completecases!\n \n \nFunction\n.\n\n\nDelete rows with NA's.\n\n\ncompletecases!\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated version\n\n\n\n\nSee also \ncompletecases\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndf\n[[\n1\n,\n4\n,\n5\n],\n \n:\nx\n]\n \n=\n \nNA\n\n\ndf\n[[\n9\n,\n10\n],\n \n:\ny\n]\n \n=\n \nNA\n\n\ncompletecases!\n(\ndf\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nStatsBase.describe\n \n \nFunction\n.\n\n\ndescribe(a)\n\n\n\n\n\nPretty-print the summary statistics provided by \nsummarystats\n: the mean, minimum, 25th percentile, median, 75th percentile, and maximum.\n\n\nsource\n\n\nSummarize the columns of an AbstractDataFrame\n\n\ndescribe\n(\ndf\n::\nAbstractDataFrame\n)\n\n\ndescribe\n(\nio\n,\n \ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nio\n : optional output descriptor\n\n\n\n\nResult\n\n\n\n\nnothing\n\n\n\n\nDetails\n\n\nIf the column's base type derives from Number, compute the minimum, first quantile, median, mean, third quantile, and maximum. NA's are filtered and reported separately.\n\n\nFor boolean columns, report trues, falses, and NAs.\n\n\nFor other types, show column characteristics and number of NAs.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndescribe\n(\ndf\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nBase.dump\n \n \nFunction\n.\n\n\nShow the structure of an AbstractDataFrame, in a tree-like format\n\n\ndump\n(\ndf\n::\nAbstractDataFrame\n,\n \nn\n::\nInt\n \n=\n \n5\n)\n\n\ndump\n(\nio\n::\nIO\n,\n \ndf\n::\nAbstractDataFrame\n,\n \nn\n::\nInt\n \n=\n \n5\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nn\n : the number of levels to show\n\n\nio\n : optional output descriptor\n\n\n\n\nResult\n\n\n\n\nnothing\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nstr\n(\ndf\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.names!\n \n \nFunction\n.\n\n\nSet column names\n\n\nnames!\n(\ndf\n::\nAbstractDataFrame\n,\n \nvals\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nvals\n : column names, normally a Vector{Symbol} the same length as the number of columns in \ndf\n\n\nallow_duplicates\n : if \nfalse\n (the default), an error will be raised if duplicate names are found; if \ntrue\n, duplicate names will be suffixed with \n_i\n (\ni\n starting at 1 for the first duplicate).\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated result\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nnames!\n(\ndf\n,\n \n[\n:\na\n,\n \n:\nb\n,\n \n:\nc\n])\n\n\nnames!\n(\ndf\n,\n \n[\n:\na\n,\n \n:\nb\n,\n \n:\na\n])\n  \n# throws ArgumentError\n\n\nnames!\n(\ndf\n,\n \n[\n:\na\n,\n \n:\nb\n,\n \n:\na\n],\n \nallow_duplicates\n=\ntrue\n)\n  \n# renames second :a to :a_1\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.nonunique\n \n \nFunction\n.\n\n\nIndexes of complete cases (rows without NA's)\n\n\nnonunique\n(\ndf\n::\nAbstractDataFrame\n)\n\n\nnonunique\n(\ndf\n::\nAbstractDataFrame\n,\n \ncols\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\ncols\n : a column indicator (Symbol, Int, Vector{Symbol}, etc.) specifying the column(s) to compare\n\n\n\n\nResult\n\n\n\n\n::Vector{Bool}\n : indicates whether the row is a duplicate of some prior row\n\n\n\n\nSee also \nunique\n and \nunique!\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndf\n \n=\n \nvcat\n(\ndf\n,\n \ndf\n)\n\n\nnonunique\n(\ndf\n)\n\n\nnonunique\n(\ndf\n,\n \n1\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.rename\n \n \nFunction\n.\n\n\nRename columns\n\n\nrename!\n(\ndf\n::\nAbstractDataFrame\n,\n \nfrom\n::\nSymbol\n,\n \nto\n::\nSymbol\n)\n\n\nrename!\n(\ndf\n::\nAbstractDataFrame\n,\n \nd\n::\nAssociative\n)\n\n\nrename!\n(\nf\n::\nFunction\n,\n \ndf\n::\nAbstractDataFrame\n)\n\n\nrename\n(\ndf\n::\nAbstractDataFrame\n,\n \nfrom\n::\nSymbol\n,\n \nto\n::\nSymbol\n)\n\n\nrename\n(\nf\n::\nFunction\n,\n \ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nd\n : an Associative type that maps the original name to a new name\n\n\nf\n : a function that has the old column name (a symbol) as input and new column name (a symbol) as output\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated result\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nrename\n(\nx\n \n-\n \nSymbol\n(\nuppercase\n(\nstring\n(\nx\n))),\n \ndf\n)\n\n\nrename\n(\ndf\n,\n \nDict\n(\n:\ni\n=\n:\nA\n,\n \n:\nx\n=\n:\nX\n))\n\n\nrename\n(\ndf\n,\n \n:\ny\n,\n \n:\nY\n)\n\n\nrename!\n(\ndf\n,\n \nDict\n(\n:\ni\n=\n:\nA\n,\n \n:\nx\n=\n:\nX\n))\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.rename!\n \n \nFunction\n.\n\n\nRename columns\n\n\nrename!\n(\ndf\n::\nAbstractDataFrame\n,\n \nfrom\n::\nSymbol\n,\n \nto\n::\nSymbol\n)\n\n\nrename!\n(\ndf\n::\nAbstractDataFrame\n,\n \nd\n::\nAssociative\n)\n\n\nrename!\n(\nf\n::\nFunction\n,\n \ndf\n::\nAbstractDataFrame\n)\n\n\nrename\n(\ndf\n::\nAbstractDataFrame\n,\n \nfrom\n::\nSymbol\n,\n \nto\n::\nSymbol\n)\n\n\nrename\n(\nf\n::\nFunction\n,\n \ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nd\n : an Associative type that maps the original name to a new name\n\n\nf\n : a function that has the old column name (a symbol) as input and new column name (a symbol) as output\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated result\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nrename\n(\nx\n \n-\n \nSymbol\n(\nuppercase\n(\nstring\n(\nx\n))),\n \ndf\n)\n\n\nrename\n(\ndf\n,\n \nDict\n(\n:\ni\n=\n:\nA\n,\n \n:\nx\n=\n:\nX\n))\n\n\nrename\n(\ndf\n,\n \n:\ny\n,\n \n:\nY\n)\n\n\nrename!\n(\ndf\n,\n \nDict\n(\n:\ni\n=\n:\nA\n,\n \n:\nx\n=\n:\nX\n))\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.tail\n \n \nFunction\n.\n\n\nShow the first or last part of an AbstractDataFrame\n\n\nhead\n(\ndf\n::\nAbstractDataFrame\n,\n \nr\n::\nInt\n \n=\n \n6\n)\n\n\ntail\n(\ndf\n::\nAbstractDataFrame\n,\n \nr\n::\nInt\n \n=\n \n6\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nr\n : the number of rows to show\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the first or last part of \ndf\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nhead\n(\ndf\n)\n\n\ntail\n(\ndf\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nBase.unique\n \n \nFunction\n.\n\n\nDelete duplicate rows\n\n\nunique\n(\ndf\n::\nAbstractDataFrame\n)\n\n\nunique\n(\ndf\n::\nAbstractDataFrame\n,\n \ncols\n)\n\n\nunique!\n(\ndf\n::\nAbstractDataFrame\n)\n\n\nunique!\n(\ndf\n::\nAbstractDataFrame\n,\n \ncols\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\ncols\n :  column indicator (Symbol, Int, Vector{Symbol}, etc.)\n\n\n\n\nspecifying the column(s) to compare.\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated version of \ndf\n with unique rows.\n\n\n\n\nWhen \ncols\n is specified, the return DataFrame contains complete rows, retaining in each case the first instance for which \ndf[cols]\n is unique.\n\n\nSee also \nnonunique\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndf\n \n=\n \nvcat\n(\ndf\n,\n \ndf\n)\n\n\nunique\n(\ndf\n)\n   \n# doesn\nt modify df\n\n\nunique\n(\ndf\n,\n \n1\n)\n\n\nunique!\n(\ndf\n)\n  \n# modifies df\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.unique!\n \n \nFunction\n.\n\n\nDelete duplicate rows\n\n\nunique\n(\ndf\n::\nAbstractDataFrame\n)\n\n\nunique\n(\ndf\n::\nAbstractDataFrame\n,\n \ncols\n)\n\n\nunique!\n(\ndf\n::\nAbstractDataFrame\n)\n\n\nunique!\n(\ndf\n::\nAbstractDataFrame\n,\n \ncols\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\ncols\n :  column indicator (Symbol, Int, Vector{Symbol}, etc.)\n\n\n\n\nspecifying the column(s) to compare.\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated version of \ndf\n with unique rows.\n\n\n\n\nWhen \ncols\n is specified, the return DataFrame contains complete rows, retaining in each case the first instance for which \ndf[cols]\n is unique.\n\n\nSee also \nnonunique\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndf\n \n=\n \nvcat\n(\ndf\n,\n \ndf\n)\n\n\nunique\n(\ndf\n)\n   \n# doesn\nt modify df\n\n\nunique\n(\ndf\n,\n \n1\n)\n\n\nunique!\n(\ndf\n)\n  \n# modifies df\n\n\n\n\n\n\nsource", 
            "title": "Utilities"
        }, 
        {
            "location": "/lib/utilities/#utilities", 
            "text": "Base.dump  Base.unique  DataFrames.completecases  DataFrames.completecases!  DataFrames.eltypes  DataFrames.head  DataFrames.names!  DataFrames.nonunique  DataFrames.rename  DataFrames.rename!  DataFrames.tail  DataFrames.unique!  StatsBase.describe   ...  #  DataFrames.eltypes     Function .  Column elemental types  eltypes ( df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame   Result   ::Vector{Type}  : the elemental type of each column   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  eltypes ( df )   source  #  DataFrames.head     Function .  Show the first or last part of an AbstractDataFrame  head ( df :: AbstractDataFrame ,   r :: Int   =   6 )  tail ( df :: AbstractDataFrame ,   r :: Int   =   6 )   Arguments   df  : the AbstractDataFrame  r  : the number of rows to show   Result   ::AbstractDataFrame  : the first or last part of  df   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  head ( df )  tail ( df )   source  #  DataFrames.completecases     Function .  Indexes of complete cases (rows without NA's)  completecases ( df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame   Result   ::Vector{Bool}  : indexes of complete cases   See also  completecases! .  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  df [[ 1 , 4 , 5 ],   : x ]   =   NA  df [[ 9 , 10 ],   : y ]   =   NA  completecases ( df )   source  #  DataFrames.completecases!     Function .  Delete rows with NA's.  completecases! ( df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame   Result   ::AbstractDataFrame  : the updated version   See also  completecases .  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  df [[ 1 , 4 , 5 ],   : x ]   =   NA  df [[ 9 , 10 ],   : y ]   =   NA  completecases! ( df )   source  #  StatsBase.describe     Function .  describe(a)  Pretty-print the summary statistics provided by  summarystats : the mean, minimum, 25th percentile, median, 75th percentile, and maximum.  source  Summarize the columns of an AbstractDataFrame  describe ( df :: AbstractDataFrame )  describe ( io ,   df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame  io  : optional output descriptor   Result   nothing   Details  If the column's base type derives from Number, compute the minimum, first quantile, median, mean, third quantile, and maximum. NA's are filtered and reported separately.  For boolean columns, report trues, falses, and NAs.  For other types, show column characteristics and number of NAs.  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  describe ( df )   source  #  Base.dump     Function .  Show the structure of an AbstractDataFrame, in a tree-like format  dump ( df :: AbstractDataFrame ,   n :: Int   =   5 )  dump ( io :: IO ,   df :: AbstractDataFrame ,   n :: Int   =   5 )   Arguments   df  : the AbstractDataFrame  n  : the number of levels to show  io  : optional output descriptor   Result   nothing   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  str ( df )   source  #  DataFrames.names!     Function .  Set column names  names! ( df :: AbstractDataFrame ,   vals )   Arguments   df  : the AbstractDataFrame  vals  : column names, normally a Vector{Symbol} the same length as the number of columns in  df  allow_duplicates  : if  false  (the default), an error will be raised if duplicate names are found; if  true , duplicate names will be suffixed with  _i  ( i  starting at 1 for the first duplicate).   Result   ::AbstractDataFrame  : the updated result   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  names! ( df ,   [ : a ,   : b ,   : c ])  names! ( df ,   [ : a ,   : b ,   : a ])    # throws ArgumentError  names! ( df ,   [ : a ,   : b ,   : a ],   allow_duplicates = true )    # renames second :a to :a_1   source  #  DataFrames.nonunique     Function .  Indexes of complete cases (rows without NA's)  nonunique ( df :: AbstractDataFrame )  nonunique ( df :: AbstractDataFrame ,   cols )   Arguments   df  : the AbstractDataFrame  cols  : a column indicator (Symbol, Int, Vector{Symbol}, etc.) specifying the column(s) to compare   Result   ::Vector{Bool}  : indicates whether the row is a duplicate of some prior row   See also  unique  and  unique! .  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  df   =   vcat ( df ,   df )  nonunique ( df )  nonunique ( df ,   1 )   source  #  DataFrames.rename     Function .  Rename columns  rename! ( df :: AbstractDataFrame ,   from :: Symbol ,   to :: Symbol )  rename! ( df :: AbstractDataFrame ,   d :: Associative )  rename! ( f :: Function ,   df :: AbstractDataFrame )  rename ( df :: AbstractDataFrame ,   from :: Symbol ,   to :: Symbol )  rename ( f :: Function ,   df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame  d  : an Associative type that maps the original name to a new name  f  : a function that has the old column name (a symbol) as input and new column name (a symbol) as output   Result   ::AbstractDataFrame  : the updated result   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  rename ( x   -   Symbol ( uppercase ( string ( x ))),   df )  rename ( df ,   Dict ( : i = : A ,   : x = : X ))  rename ( df ,   : y ,   : Y )  rename! ( df ,   Dict ( : i = : A ,   : x = : X ))   source  #  DataFrames.rename!     Function .  Rename columns  rename! ( df :: AbstractDataFrame ,   from :: Symbol ,   to :: Symbol )  rename! ( df :: AbstractDataFrame ,   d :: Associative )  rename! ( f :: Function ,   df :: AbstractDataFrame )  rename ( df :: AbstractDataFrame ,   from :: Symbol ,   to :: Symbol )  rename ( f :: Function ,   df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame  d  : an Associative type that maps the original name to a new name  f  : a function that has the old column name (a symbol) as input and new column name (a symbol) as output   Result   ::AbstractDataFrame  : the updated result   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  rename ( x   -   Symbol ( uppercase ( string ( x ))),   df )  rename ( df ,   Dict ( : i = : A ,   : x = : X ))  rename ( df ,   : y ,   : Y )  rename! ( df ,   Dict ( : i = : A ,   : x = : X ))   source  #  DataFrames.tail     Function .  Show the first or last part of an AbstractDataFrame  head ( df :: AbstractDataFrame ,   r :: Int   =   6 )  tail ( df :: AbstractDataFrame ,   r :: Int   =   6 )   Arguments   df  : the AbstractDataFrame  r  : the number of rows to show   Result   ::AbstractDataFrame  : the first or last part of  df   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  head ( df )  tail ( df )   source  #  Base.unique     Function .  Delete duplicate rows  unique ( df :: AbstractDataFrame )  unique ( df :: AbstractDataFrame ,   cols )  unique! ( df :: AbstractDataFrame )  unique! ( df :: AbstractDataFrame ,   cols )   Arguments   df  : the AbstractDataFrame  cols  :  column indicator (Symbol, Int, Vector{Symbol}, etc.)   specifying the column(s) to compare.  Result   ::AbstractDataFrame  : the updated version of  df  with unique rows.   When  cols  is specified, the return DataFrame contains complete rows, retaining in each case the first instance for which  df[cols]  is unique.  See also  nonunique .  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  df   =   vcat ( df ,   df )  unique ( df )     # doesn t modify df  unique ( df ,   1 )  unique! ( df )    # modifies df   source  #  DataFrames.unique!     Function .  Delete duplicate rows  unique ( df :: AbstractDataFrame )  unique ( df :: AbstractDataFrame ,   cols )  unique! ( df :: AbstractDataFrame )  unique! ( df :: AbstractDataFrame ,   cols )   Arguments   df  : the AbstractDataFrame  cols  :  column indicator (Symbol, Int, Vector{Symbol}, etc.)   specifying the column(s) to compare.  Result   ::AbstractDataFrame  : the updated version of  df  with unique rows.   When  cols  is specified, the return DataFrame contains complete rows, retaining in each case the first instance for which  df[cols]  is unique.  See also  nonunique .  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  df   =   vcat ( df ,   df )  unique ( df )     # doesn t modify df  unique ( df ,   1 )  unique! ( df )    # modifies df   source", 
            "title": "Utilities"
        }, 
        {
            "location": "/lib/manipulation/", 
            "text": "Data Manipulation\n\n\n\n\nBase.join\n\n\nDataFrames.melt\n\n\nDataFrames.meltdf\n\n\nDataFrames.stack\n\n\nDataFrames.stackdf\n\n\nDataFrames.unstack\n\n\n\n\n\n\nJoins\n\n\n#\n\n\nBase.join\n \n \nFunction\n.\n\n\nJoin two DataFrames\n\n\njoin\n(\ndf1\n::\nAbstractDataFrame\n,\n\n     \ndf2\n::\nAbstractDataFrame\n;\n\n     \non\n::\nUnion\n{\nSymbol\n,\n \nVector\n{\nSymbol\n}}\n \n=\n \nSymbol\n[],\n\n     \nkind\n::\nSymbol\n \n=\n \n:\ninner\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf1\n, \ndf2\n : the two AbstractDataFrames to be joined\n\n\n\n\nKeyword Arguments\n\n\n\n\non\n : a Symbol or Vector{Symbol}, the column(s) used as keys when joining; required argument except for \nkind = :cross\n\n\n\n\nkind\n : the type of join, options include:\n\n\n\n\n:inner\n : only include rows with keys that match in both \ndf1\n and \ndf2\n, the default\n\n\n:outer\n : include all rows from \ndf1\n and \ndf2\n\n\n:left\n : include all rows from \ndf1\n\n\n:right\n : include all rows from \ndf2\n\n\n:semi\n : return rows of \ndf1\n that match with the keys in \ndf2\n\n\n:anti\n : return rows of \ndf1\n that do not match with the keys in \ndf2\n\n\n:cross\n : a full Cartesian product of the key combinations; every row of \ndf1\n is matched with every row of \ndf2\n\n\n\n\n\n\n\n\nNA\ns are filled in where needed to complete joins.\n\n\nResult\n\n\n\n\n::DataFrame\n : the joined DataFrame\n\n\n\n\nExamples\n\n\nname\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n1\n,\n \n2\n,\n \n3\n],\n \nName\n \n=\n \n[\nJohn Doe\n,\n \nJane Doe\n,\n \nJoe Blogs\n])\n\n\njob\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n1\n,\n \n2\n,\n \n4\n],\n \nJob\n \n=\n \n[\nLawyer\n,\n \nDoctor\n,\n \nFarmer\n])\n\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nouter\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nleft\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nright\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nsemi\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nanti\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \nkind\n \n=\n \n:\ncross\n)\n\n\n\n\n\n\nsource\n\n\n\n\nReshaping\n\n\n#\n\n\nDataFrames.melt\n \n \nFunction\n.\n\n\nStacks a DataFrame; convert from a wide to long format; see \nstack\n.\n\n\nsource\n\n\n#\n\n\nDataFrames.stack\n \n \nFunction\n.\n\n\nStacks a DataFrame; convert from a wide to long format\n\n\nstack\n(\ndf\n::\nAbstractDataFrame\n,\n \nmeasure_vars\n,\n \nid_vars\n)\n\n\nstack\n(\ndf\n::\nAbstractDataFrame\n,\n \nmeasure_vars\n)\n\n\nstack\n(\ndf\n::\nAbstractDataFrame\n)\n\n\nmelt\n(\ndf\n::\nAbstractDataFrame\n,\n \nid_vars\n,\n \nmeasure_vars\n)\n\n\nmelt\n(\ndf\n::\nAbstractDataFrame\n,\n \nid_vars\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame to be stacked\n\n\nmeasure_vars\n : the columns to be stacked (the measurement variables), a normal column indexing type, like a Symbol, Vector{Symbol}, Int, etc.; for \nmelt\n, defaults to all variables that are not \nid_vars\n\n\nid_vars\n : the identifier columns that are repeated during stacking, a normal column indexing type; for \nstack\n defaults to all variables that are not \nmeasure_vars\n\n\n\n\nIf neither \nmeasure_vars\n or \nid_vars\n are given, \nmeasure_vars\n defaults to all floating point columns.\n\n\nResult\n\n\n\n\n::DataFrame\n : the long-format dataframe with column \n:value\n holding the values of the stacked columns (\nmeasure_vars\n), with column \n:variable\n a Vector of Symbols with the \nmeasure_vars\n name, and with columns for each of the \nid_vars\n.\n\n\n\n\nSee also \nstackdf\n and \nmeltdf\n for stacking methods that return a view into the original DataFrame. See \nunstack\n for converting from long to wide format.\n\n\nExamples\n\n\nd1\n \n=\n \nDataFrame\n(\na\n \n=\n \nrepeat\n([\n1\n:\n3\n;],\n \ninner\n \n=\n \n[\n4\n]),\n\n               \nb\n \n=\n \nrepeat\n([\n1\n:\n4\n;],\n \ninner\n \n=\n \n[\n3\n]),\n\n               \nc\n \n=\n \nrandn\n(\n12\n),\n\n               \nd\n \n=\n \nrandn\n(\n12\n),\n\n               \ne\n \n=\n \nmap\n(\nstring\n,\n \na\n:\nl\n))\n\n\n\nd1s\n \n=\n \nstack\n(\nd1\n,\n \n[\n:\nc\n,\n \n:\nd\n])\n\n\nd1s2\n \n=\n \nstack\n(\nd1\n,\n \n[\n:\nc\n,\n \n:\nd\n],\n \n[\n:\na\n])\n\n\nd1m\n \n=\n \nmelt\n(\nd1\n,\n \n[\n:\na\n,\n \n:\nb\n,\n \n:\ne\n])\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.unstack\n \n \nFunction\n.\n\n\nUnstacks a DataFrame; convert from a long to wide format\n\n\nunstack\n(\ndf\n::\nAbstractDataFrame\n,\n \nrowkey\n,\n \ncolkey\n,\n \nvalue\n)\n\n\nunstack\n(\ndf\n::\nAbstractDataFrame\n,\n \ncolkey\n,\n \nvalue\n)\n\n\nunstack\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame to be unstacked\n\n\nrowkey\n : the column with a unique key for each row, if not given, find a key by grouping on anything not a \ncolkey\n or \nvalue\n\n\ncolkey\n : the column holding the column names in wide format, defaults to \n:variable\n\n\nvalue\n : the value column, defaults to \n:value\n\n\n\n\nResult\n\n\n\n\n::DataFrame\n : the wide-format dataframe\n\n\n\n\nExamples\n\n\nwide\n \n=\n \nDataFrame\n(\nid\n \n=\n \n1\n:\n12\n,\n\n                 \na\n  \n=\n \nrepeat\n([\n1\n:\n3\n;],\n \ninner\n \n=\n \n[\n4\n]),\n\n                 \nb\n  \n=\n \nrepeat\n([\n1\n:\n4\n;],\n \ninner\n \n=\n \n[\n3\n]),\n\n                 \nc\n  \n=\n \nrandn\n(\n12\n),\n\n                 \nd\n  \n=\n \nrandn\n(\n12\n))\n\n\n\nlong\n \n=\n \nstack\n(\nwide\n)\n\n\nwide0\n \n=\n \nunstack\n(\nlong\n)\n\n\nwide1\n \n=\n \nunstack\n(\nlong\n,\n \n:\nvariable\n,\n \n:\nvalue\n)\n\n\nwide2\n \n=\n \nunstack\n(\nlong\n,\n \n:\nid\n,\n \n:\nvariable\n,\n \n:\nvalue\n)\n\n\n\n\n\n\nNote that there are some differences between the widened results above.\n\n\nsource\n\n\n#\n\n\nDataFrames.stackdf\n \n \nFunction\n.\n\n\nA stacked view of a DataFrame (long format)\n\n\nLike \nstack\n and \nmelt\n, but a view is returned rather than data copies.\n\n\nstackdf\n(\ndf\n::\nAbstractDataFrame\n,\n \nmeasure_vars\n,\n \nid_vars\n)\n\n\nstackdf\n(\ndf\n::\nAbstractDataFrame\n,\n \nmeasure_vars\n)\n\n\nmeltdf\n(\ndf\n::\nAbstractDataFrame\n,\n \nid_vars\n,\n \nmeasure_vars\n)\n\n\nmeltdf\n(\ndf\n::\nAbstractDataFrame\n,\n \nid_vars\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the wide AbstractDataFrame\n\n\nmeasure_vars\n : the columns to be stacked (the measurement variables), a normal column indexing type, like a Symbol, Vector{Symbol}, Int, etc.; for \nmelt\n, defaults to all variables that are not \nid_vars\n\n\nid_vars\n : the identifier columns that are repeated during stacking, a normal column indexing type; for \nstack\n defaults to all variables that are not \nmeasure_vars\n\n\n\n\nResult\n\n\n\n\n::DataFrame\n : the long-format dataframe with column \n:value\n holding the values of the stacked columns (\nmeasure_vars\n), with column \n:variable\n a Vector of Symbols with the \nmeasure_vars\n name, and with columns for each of the \nid_vars\n.\n\n\n\n\nThe result is a view because the columns are special AbstractVectors that return indexed views into the original DataFrame.\n\n\nExamples\n\n\nd1\n \n=\n \nDataFrame\n(\na\n \n=\n \nrepeat\n([\n1\n:\n3\n;],\n \ninner\n \n=\n \n[\n4\n]),\n\n               \nb\n \n=\n \nrepeat\n([\n1\n:\n4\n;],\n \ninner\n \n=\n \n[\n3\n]),\n\n               \nc\n \n=\n \nrandn\n(\n12\n),\n\n               \nd\n \n=\n \nrandn\n(\n12\n),\n\n               \ne\n \n=\n \nmap\n(\nstring\n,\n \na\n:\nl\n))\n\n\n\nd1s\n \n=\n \nstackdf\n(\nd1\n,\n \n[\n:\nc\n,\n \n:\nd\n])\n\n\nd1s2\n \n=\n \nstackdf\n(\nd1\n,\n \n[\n:\nc\n,\n \n:\nd\n],\n \n[\n:\na\n])\n\n\nd1m\n \n=\n \nmeltdf\n(\nd1\n,\n \n[\n:\na\n,\n \n:\nb\n,\n \n:\ne\n])\n\n\n\n\n\n\nsource\n\n\n#\n\n\nDataFrames.meltdf\n \n \nFunction\n.\n\n\nA stacked view of a DataFrame (long format); see \nstackdf\n\n\nsource", 
            "title": "Data manipulation"
        }, 
        {
            "location": "/lib/manipulation/#data-manipulation", 
            "text": "Base.join  DataFrames.melt  DataFrames.meltdf  DataFrames.stack  DataFrames.stackdf  DataFrames.unstack", 
            "title": "Data Manipulation"
        }, 
        {
            "location": "/lib/manipulation/#joins", 
            "text": "#  Base.join     Function .  Join two DataFrames  join ( df1 :: AbstractDataFrame , \n      df2 :: AbstractDataFrame ; \n      on :: Union { Symbol ,   Vector { Symbol }}   =   Symbol [], \n      kind :: Symbol   =   : inner )   Arguments   df1 ,  df2  : the two AbstractDataFrames to be joined   Keyword Arguments   on  : a Symbol or Vector{Symbol}, the column(s) used as keys when joining; required argument except for  kind = :cross   kind  : the type of join, options include:   :inner  : only include rows with keys that match in both  df1  and  df2 , the default  :outer  : include all rows from  df1  and  df2  :left  : include all rows from  df1  :right  : include all rows from  df2  :semi  : return rows of  df1  that match with the keys in  df2  :anti  : return rows of  df1  that do not match with the keys in  df2  :cross  : a full Cartesian product of the key combinations; every row of  df1  is matched with every row of  df2     NA s are filled in where needed to complete joins.  Result   ::DataFrame  : the joined DataFrame   Examples  name   =   DataFrame ( ID   =   [ 1 ,   2 ,   3 ],   Name   =   [ John Doe ,   Jane Doe ,   Joe Blogs ])  job   =   DataFrame ( ID   =   [ 1 ,   2 ,   4 ],   Job   =   [ Lawyer ,   Doctor ,   Farmer ])  join ( name ,   job ,   on   =   : ID )  join ( name ,   job ,   on   =   : ID ,   kind   =   : outer )  join ( name ,   job ,   on   =   : ID ,   kind   =   : left )  join ( name ,   job ,   on   =   : ID ,   kind   =   : right )  join ( name ,   job ,   on   =   : ID ,   kind   =   : semi )  join ( name ,   job ,   on   =   : ID ,   kind   =   : anti )  join ( name ,   job ,   kind   =   : cross )   source", 
            "title": "Joins"
        }, 
        {
            "location": "/lib/manipulation/#reshaping", 
            "text": "#  DataFrames.melt     Function .  Stacks a DataFrame; convert from a wide to long format; see  stack .  source  #  DataFrames.stack     Function .  Stacks a DataFrame; convert from a wide to long format  stack ( df :: AbstractDataFrame ,   measure_vars ,   id_vars )  stack ( df :: AbstractDataFrame ,   measure_vars )  stack ( df :: AbstractDataFrame )  melt ( df :: AbstractDataFrame ,   id_vars ,   measure_vars )  melt ( df :: AbstractDataFrame ,   id_vars )   Arguments   df  : the AbstractDataFrame to be stacked  measure_vars  : the columns to be stacked (the measurement variables), a normal column indexing type, like a Symbol, Vector{Symbol}, Int, etc.; for  melt , defaults to all variables that are not  id_vars  id_vars  : the identifier columns that are repeated during stacking, a normal column indexing type; for  stack  defaults to all variables that are not  measure_vars   If neither  measure_vars  or  id_vars  are given,  measure_vars  defaults to all floating point columns.  Result   ::DataFrame  : the long-format dataframe with column  :value  holding the values of the stacked columns ( measure_vars ), with column  :variable  a Vector of Symbols with the  measure_vars  name, and with columns for each of the  id_vars .   See also  stackdf  and  meltdf  for stacking methods that return a view into the original DataFrame. See  unstack  for converting from long to wide format.  Examples  d1   =   DataFrame ( a   =   repeat ([ 1 : 3 ;],   inner   =   [ 4 ]), \n                b   =   repeat ([ 1 : 4 ;],   inner   =   [ 3 ]), \n                c   =   randn ( 12 ), \n                d   =   randn ( 12 ), \n                e   =   map ( string ,   a : l ))  d1s   =   stack ( d1 ,   [ : c ,   : d ])  d1s2   =   stack ( d1 ,   [ : c ,   : d ],   [ : a ])  d1m   =   melt ( d1 ,   [ : a ,   : b ,   : e ])   source  #  DataFrames.unstack     Function .  Unstacks a DataFrame; convert from a long to wide format  unstack ( df :: AbstractDataFrame ,   rowkey ,   colkey ,   value )  unstack ( df :: AbstractDataFrame ,   colkey ,   value )  unstack ( df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame to be unstacked  rowkey  : the column with a unique key for each row, if not given, find a key by grouping on anything not a  colkey  or  value  colkey  : the column holding the column names in wide format, defaults to  :variable  value  : the value column, defaults to  :value   Result   ::DataFrame  : the wide-format dataframe   Examples  wide   =   DataFrame ( id   =   1 : 12 , \n                  a    =   repeat ([ 1 : 3 ;],   inner   =   [ 4 ]), \n                  b    =   repeat ([ 1 : 4 ;],   inner   =   [ 3 ]), \n                  c    =   randn ( 12 ), \n                  d    =   randn ( 12 ))  long   =   stack ( wide )  wide0   =   unstack ( long )  wide1   =   unstack ( long ,   : variable ,   : value )  wide2   =   unstack ( long ,   : id ,   : variable ,   : value )   Note that there are some differences between the widened results above.  source  #  DataFrames.stackdf     Function .  A stacked view of a DataFrame (long format)  Like  stack  and  melt , but a view is returned rather than data copies.  stackdf ( df :: AbstractDataFrame ,   measure_vars ,   id_vars )  stackdf ( df :: AbstractDataFrame ,   measure_vars )  meltdf ( df :: AbstractDataFrame ,   id_vars ,   measure_vars )  meltdf ( df :: AbstractDataFrame ,   id_vars )   Arguments   df  : the wide AbstractDataFrame  measure_vars  : the columns to be stacked (the measurement variables), a normal column indexing type, like a Symbol, Vector{Symbol}, Int, etc.; for  melt , defaults to all variables that are not  id_vars  id_vars  : the identifier columns that are repeated during stacking, a normal column indexing type; for  stack  defaults to all variables that are not  measure_vars   Result   ::DataFrame  : the long-format dataframe with column  :value  holding the values of the stacked columns ( measure_vars ), with column  :variable  a Vector of Symbols with the  measure_vars  name, and with columns for each of the  id_vars .   The result is a view because the columns are special AbstractVectors that return indexed views into the original DataFrame.  Examples  d1   =   DataFrame ( a   =   repeat ([ 1 : 3 ;],   inner   =   [ 4 ]), \n                b   =   repeat ([ 1 : 4 ;],   inner   =   [ 3 ]), \n                c   =   randn ( 12 ), \n                d   =   randn ( 12 ), \n                e   =   map ( string ,   a : l ))  d1s   =   stackdf ( d1 ,   [ : c ,   : d ])  d1s2   =   stackdf ( d1 ,   [ : c ,   : d ],   [ : a ])  d1m   =   meltdf ( d1 ,   [ : a ,   : b ,   : e ])   source  #  DataFrames.meltdf     Function .  A stacked view of a DataFrame (long format); see  stackdf  source", 
            "title": "Reshaping"
        }, 
        {
            "location": "/NEWS/", 
            "text": "DataFrames v0.6.11 Release Notes\n\n\n\n\nChanges\n\n\n\n\nNew documentation based on Documenter ([#929])\n\n\nSupport new fit indicator functions for statistical models ([#921]).\n\n\nAdd string literals csv, csv2, wsv, and tsv ([#918])\n\n\nAdd a readtable argument for optional name normalization ([#896])\n\n\n\n\n\n\nDataFrames v0.6.6 Release Notes\n\n\n\n\nDeprecations\n\n\n\n\nDeprecates \narray(df, ...)\n in favor of \nconvert(Array, df, ...)\n ([#806])\n\n\nDeprecates \nDataArray(df, T)\n in favor of \nconvert(DataArray{T}, df)\n ([#806])\n\n\n\n\n\n\nDataFrames v0.6.3 Release Notes\n\n\n\n\nDeprecations\n\n\n\n\nRemoves \nsave\n and \nloaddf\n, since the format was not compatible across Julia and DataFrames versions ([#790]). Use \nwritetable\n or \nJLD\n to save DataFrames\n\n\n\n\n\n\nDataFrames v0.6.1 Release Notes\n\n\n\n\nNew features\n\n\n\n\nwritetable\n supports \nappend\n option ([#755])\n\n\n\n\n\n\nChanges\n\n\n\n\nFaster \nread_rda\n ([#754], [#759])\n\n\n\n\n\n\nDataFrames v0.6.0 Release Notes\n\n\nFocus on performance improvements and rooting out bugs in corner cases.\n\n\n\n\nNew features\n\n\n\n\nConstructor for empty DataFrames allows specifying PDAs ([#725])\n\n\nstack(df)\n and \nmelt(df)\n, which take FloatingPoint vars as measure vars ([#734])\n\n\nNew convenience methods for \nunstack\n ([#734])\n\n\nconvertdataframes\n option added to \nread_rda\n ([#751])\n\n\n\n\n\n\nChanges\n\n\n\n\nvcat(dfs)\n handles container and eltype promotion ([#747])\n\n\njoin\n finally handles DataFrames with no non-key columns ([#749])\n\n\nsorting methods throw an error when args meant for \ncols\n are passed to \nby\n ([#749])\n\n\nrename!\n and \nrename\n throw when column to be renamed does not exist ([#749])\n\n\nnames!\n, \nrename!\n, and \nrename\n for DataFrames now return DataFrames ([#749])\n\n\n\n\n\n\nDeprecations\n\n\n\n\nDeprecates \nby(df, cols, [symbol(s)])\n in favor of \naggregate(df, cols, [function(s)])\n ([#726])\n\n\nRemoves \npivottable\n in favor of other reshaping methods ([#734])\n\n\nDeprecates \nnullable!(..., ::AbstractDataFrame)\n in favor of \nnullable!(::DataFrame, ...)\n ([#752])\n\n\nDeprecates \nkeys(df)\n, \nvalues(df)\n ([#752])\n\n\nRenames \ninsert!(df, df)\n to \nmerge!(df, dfs...)\n ([#752])\n\n\n\n\n\n\nDataFrames v0.5.12 Release Notes\n\n\nTrack changes to JuliaLang/julia\n\n\n\n\nDataFrames v0.5.11 Release Notes\n\n\nTrack changes to JuliaLang/julia\n\n\n\n\nDataFrames v0.5.10 Release Notes\n\n\n\n\nNew features\n\n\n\n\nFormulas handle three-way (and higher) interactions ([#700])\n\n\n\n\n\n\nChanges\n\n\n\n\nNow using ReadTheDocs for documentation\n\n\n\n\n\n\nDataFrames v0.5.9 Release Notes\n\n\nTrack changes to JuliaLang/julia\n\n\n\n\nDataFrames v0.5.8 Release Notes\n\n\n\n\nNew features\n\n\n\n\nExtends \nStatsBase.predict\n to take a DataFrame as a predictor ([#679])\n\n\ncoefnames\n handles random-effect terms ([#662])\n\n\n\n\n\n\nDeprecations\n\n\n\n\nDeprecates \nDataFrame(::Dict, ...)\n in favor of \nconvert\n ([#626])\n\n\n\n\n\n\nDataFrames v0.5.7 Release Notes\n\n\n\n\nNew features\n\n\n\n\ndeleterows!(df::DataFrame, inds)\n ([#635])\n\n\n\n\n\n\nChanges\n\n\n\n\nempty!(::DataFrame)\n and \ninsert!(::DataFrame, ...)\n now operate in place ([#634])\n\n\nAll exported higher-order functions now handle do-block syntax ([#643])\n\n\n\n\n\n\nDataFrames v0.5.6 Release Notes\n\n\nTrack changes to JuliaLang/julia\n\n\n\n\nDataFrames v0.5.5 Release Notes\n\n\n\n\nNew features\n\n\n\n\nSupport fitting arbitrary StatisticalModels ([#571])\n\n\nTest coverage now tracked via Coveralls.io ([#597])\n\n\n\n\n\n\nChanges\n\n\n\n\nshow(::AbstractDataFrame)\n now shows all columns by default\n\n\n\n\n\n\nDeprecations\n\n\n\n\nDeprecates \nDataFrame(::Any...)\n, \nDataFrame(::Associative)\n ([#610])\n\n\n\n\n\n\nDataFrames v0.5.4 Release Notes\n\n\n\n\nNew features\n\n\n\n\npush!\n methods add a row to a DataFrame ([#621])\n\n\nTest coverage now tracked via Coveralls.io ([#597])\n\n\n\n\n\n\nChanges\n\n\n\n\nIO functions ensure column names are valid symbols ([#563])\n\n\nsetindex!\n methods now return the updated DataFrame\n\n\n\n\n\n\nDeprecations\n\n\n\n\nDeprecates \nDataFrame(::Int, ::Int)\n ([#561])\n\n\n\n\n\n\nDataFrames v0.5.3 Release Notes\n\n\nInternal changes to adjust to [JuliaLang/julia#5897]\n\n\n\n\nDataFrames v0.5.2 Release Notes\n\n\nContinues trend of stripping down features and improving core functionality.\n\n\n\n\nNew features\n\n\n\n\nappend!(::AbstractDataFrame, ::AbstractDataFrame)\n ([#506])\n\n\njoin\n supports \n:semi\n-, \n:anti\n- and \n:cross\n-joins ([#524], [#536])\n\n\nImplement \neltypes\n argument in \nreadtable\n ([#497])\n\n\nRead from generic IO objects ([#499])\n\n\n\n\n\n\nChanges\n\n\n\n\nConvert to using only symbols (no more strings) for column names ([#509])\n\n\nRenames \nstack_df\n, \nmelt_df\n, \npivot_table\n to \nstackdf\n, \nmeltdf\n, \npivottable\n ([#538])\n\n\nRenames \nduplicated\n, \ndrop_duplicates!\n to \nnonunique\n, \nunique!\n ([#538])\n\n\nRenames \nload_df\n to \nloaddf\n ([#538])\n\n\nRenames \ntypes\n to \neltypes\n ([#539])\n\n\nRenames \nreadtable\n argument \ncolnames\n to \nnames\n ([#497])\n\n\n\n\n\n\nDeprecations\n\n\n\n\nRemoves expression-based indexing, including \nwith\n, \nwithin!\n, \nbased_on\n, etc. ([#492])\n\n\nRemoves \nDataStream\n ([#492])\n\n\nRemoves \nNamedArray\n ([#492])\n\n\nRemoves column groupings (\nset_groups\n, \nget_groups\n, etc.)  ([#492])\n\n\nRemoves specific colwise and rowwise functions (\nrowsums\n, \ncolnorms\n, etc.) ([#492])\n\n\nRemoves \n@DataFrame\n and \n@transform\n ([#492])\n\n\nDeprecates natural \njoin\ns: the key must be specified now ([#536])\n\n\n\n\n\n\nDataFrames v0.5.1 Release Notes\n\n\nRemoving prototype features until core functionality is farther along.\n\n\n\n\nChanges\n\n\n\n\nWrite \nFormula\ns without quoting, thanks to the \n@~\n macro ([JuliaLang/julia#4882])\n\n\nRenames \nEachCol\n, \nEachRow\n to \neachcol\n, \neachrow\n ([#474])\n\n\neachrow\n returns a \nDataFrameRow\n ([#474])\n\n\nSubDataFrames\n are now immutable ([#474])\n\n\n\n\n\n\nDeprecations\n\n\n\n\nRemoves \nIndexedVector\n ([#483])\n\n\nRemoves \nBlocks.jl\n functionality ([#483])\n\n\nRemoves methods that treat DataFrame like a matrix, e.g \nround\n, \nsin\n ([#484])\n\n\nDeprecates \nsub\n's alias \nsubset\n ([#474])\n\n\n\n\n\n\nDataFrames v0.5.0 Release Notes\n\n\nImproved I/O and more-Julian idioms.\n\n\n\n\nNew features\n\n\n\n\nWrite HTML tables via writemime ([#433])\n\n\nRead whitespace-delimited input ([#443])\n\n\nRead input with C-style escapes ([#454])\n\n\n\n\n\n\nChanges\n\n\n\n\nsort\n interface updated to better match mainline Julia ([#389])\n\n\nnames!\n, \nrename!\n, and \ndelete!\n now return the updated Index, rather than the names in the Index ([#445])\n\n\nRenames \ncoltypes\n, \ncolnames\n, \nclean_colnames!\n to \ntypes\n, \nnames\n, \ncleannames!\n ([#469])\n\n\nVarious improvements to \nprint\n/\nshow\n methods\n\n\n\n\n\n\nDeprecations\n\n\n\n\nDeprecates \nrbind\n, \ncbind\n and \nvecbind\n deprecated in favor of \nhcat\n and \nvcat\n ([#453])\n\n\n\n\n[#389]: https://github.com/JuliaStats/DataFrames.jl/issues/389 [#433]: https://github.com/JuliaStats/DataFrames.jl/issues/433 [#443]: https://github.com/JuliaStats/DataFrames.jl/issues/443 [#445]: https://github.com/JuliaStats/DataFrames.jl/issues/445 [#453]: https://github.com/JuliaStats/DataFrames.jl/issues/453 [#454]: https://github.com/JuliaStats/DataFrames.jl/issues/454 [#469]: https://github.com/JuliaStats/DataFrames.jl/issues/469 [#474]: https://github.com/JuliaStats/DataFrames.jl/issues/474 [#483]: https://github.com/JuliaStats/DataFrames.jl/issues/483 [#484]: https://github.com/JuliaStats/DataFrames.jl/issues/484 [#492]: https://github.com/JuliaStats/DataFrames.jl/issues/492 [#497]: https://github.com/JuliaStats/DataFrames.jl/issues/497 [#499]: https://github.com/JuliaStats/DataFrames.jl/issues/499 [#506]: https://github.com/JuliaStats/DataFrames.jl/issues/506 [#509]: https://github.com/JuliaStats/DataFrames.jl/issues/509 [#524]: https://github.com/JuliaStats/DataFrames.jl/issues/524 [#536]: https://github.com/JuliaStats/DataFrames.jl/issues/536 [#538]: https://github.com/JuliaStats/DataFrames.jl/issues/538 [#539]: https://github.com/JuliaStats/DataFrames.jl/issues/539 [#561]: https://github.com/JuliaStats/DataFrames.jl/issues/561 [#563]: https://github.com/JuliaStats/DataFrames.jl/issues/563 [#571]: https://github.com/JuliaStats/DataFrames.jl/issues/571 [#597]: https://github.com/JuliaStats/DataFrames.jl/issues/597 [#610]: https://github.com/JuliaStats/DataFrames.jl/issues/610 [#621]: https://github.com/JuliaStats/DataFrames.jl/issues/621 [#626]: https://github.com/JuliaStats/DataFrames.jl/issues/626 [#634]: https://github.com/JuliaStats/DataFrames.jl/issues/634 [#635]: https://github.com/JuliaStats/DataFrames.jl/issues/635 [#643]: https://github.com/JuliaStats/DataFrames.jl/issues/643 [#662]: https://github.com/JuliaStats/DataFrames.jl/issues/662 [#679]: https://github.com/JuliaStats/DataFrames.jl/issues/679 [#700]: https://github.com/JuliaStats/DataFrames.jl/issues/700 [#725]: https://github.com/JuliaStats/DataFrames.jl/issues/725 [#726]: https://github.com/JuliaStats/DataFrames.jl/issues/726 [#734]: https://github.com/JuliaStats/DataFrames.jl/issues/734 [#747]: https://github.com/JuliaStats/DataFrames.jl/issues/747 [#749]: https://github.com/JuliaStats/DataFrames.jl/issues/749 [#751]: https://github.com/JuliaStats/DataFrames.jl/issues/751 [#752]: https://github.com/JuliaStats/DataFrames.jl/issues/752 [#754]: https://github.com/JuliaStats/DataFrames.jl/issues/754 [#755]: https://github.com/JuliaStats/DataFrames.jl/issues/755 [#759]: https://github.com/JuliaStats/DataFrames.jl/issues/759 [#790]: https://github.com/JuliaStats/DataFrames.jl/issues/790 [#806]: https://github.com/JuliaStats/DataFrames.jl/issues/806\n\n\n[JuliaLang/julia#4882]: https://github.com/JuliaLang/julia/issues/4882 [JuliaLang/julia#5897]: https://github.com/JuliaLang/julia/issues/5897", 
            "title": "Release notes"
        }, 
        {
            "location": "/NEWS/#dataframes-v0611-release-notes", 
            "text": "", 
            "title": "DataFrames v0.6.11 Release Notes"
        }, 
        {
            "location": "/NEWS/#changes", 
            "text": "New documentation based on Documenter ([#929])  Support new fit indicator functions for statistical models ([#921]).  Add string literals csv, csv2, wsv, and tsv ([#918])  Add a readtable argument for optional name normalization ([#896])", 
            "title": "Changes"
        }, 
        {
            "location": "/NEWS/#dataframes-v066-release-notes", 
            "text": "", 
            "title": "DataFrames v0.6.6 Release Notes"
        }, 
        {
            "location": "/NEWS/#deprecations", 
            "text": "Deprecates  array(df, ...)  in favor of  convert(Array, df, ...)  ([#806])  Deprecates  DataArray(df, T)  in favor of  convert(DataArray{T}, df)  ([#806])", 
            "title": "Deprecations"
        }, 
        {
            "location": "/NEWS/#dataframes-v063-release-notes", 
            "text": "", 
            "title": "DataFrames v0.6.3 Release Notes"
        }, 
        {
            "location": "/NEWS/#deprecations_1", 
            "text": "Removes  save  and  loaddf , since the format was not compatible across Julia and DataFrames versions ([#790]). Use  writetable  or  JLD  to save DataFrames", 
            "title": "Deprecations"
        }, 
        {
            "location": "/NEWS/#dataframes-v061-release-notes", 
            "text": "", 
            "title": "DataFrames v0.6.1 Release Notes"
        }, 
        {
            "location": "/NEWS/#new-features", 
            "text": "writetable  supports  append  option ([#755])", 
            "title": "New features"
        }, 
        {
            "location": "/NEWS/#changes_1", 
            "text": "Faster  read_rda  ([#754], [#759])", 
            "title": "Changes"
        }, 
        {
            "location": "/NEWS/#dataframes-v060-release-notes", 
            "text": "Focus on performance improvements and rooting out bugs in corner cases.", 
            "title": "DataFrames v0.6.0 Release Notes"
        }, 
        {
            "location": "/NEWS/#new-features_1", 
            "text": "Constructor for empty DataFrames allows specifying PDAs ([#725])  stack(df)  and  melt(df) , which take FloatingPoint vars as measure vars ([#734])  New convenience methods for  unstack  ([#734])  convertdataframes  option added to  read_rda  ([#751])", 
            "title": "New features"
        }, 
        {
            "location": "/NEWS/#changes_2", 
            "text": "vcat(dfs)  handles container and eltype promotion ([#747])  join  finally handles DataFrames with no non-key columns ([#749])  sorting methods throw an error when args meant for  cols  are passed to  by  ([#749])  rename!  and  rename  throw when column to be renamed does not exist ([#749])  names! ,  rename! , and  rename  for DataFrames now return DataFrames ([#749])", 
            "title": "Changes"
        }, 
        {
            "location": "/NEWS/#deprecations_2", 
            "text": "Deprecates  by(df, cols, [symbol(s)])  in favor of  aggregate(df, cols, [function(s)])  ([#726])  Removes  pivottable  in favor of other reshaping methods ([#734])  Deprecates  nullable!(..., ::AbstractDataFrame)  in favor of  nullable!(::DataFrame, ...)  ([#752])  Deprecates  keys(df) ,  values(df)  ([#752])  Renames  insert!(df, df)  to  merge!(df, dfs...)  ([#752])", 
            "title": "Deprecations"
        }, 
        {
            "location": "/NEWS/#dataframes-v0512-release-notes", 
            "text": "Track changes to JuliaLang/julia", 
            "title": "DataFrames v0.5.12 Release Notes"
        }, 
        {
            "location": "/NEWS/#dataframes-v0511-release-notes", 
            "text": "Track changes to JuliaLang/julia", 
            "title": "DataFrames v0.5.11 Release Notes"
        }, 
        {
            "location": "/NEWS/#dataframes-v0510-release-notes", 
            "text": "", 
            "title": "DataFrames v0.5.10 Release Notes"
        }, 
        {
            "location": "/NEWS/#new-features_2", 
            "text": "Formulas handle three-way (and higher) interactions ([#700])", 
            "title": "New features"
        }, 
        {
            "location": "/NEWS/#changes_3", 
            "text": "Now using ReadTheDocs for documentation", 
            "title": "Changes"
        }, 
        {
            "location": "/NEWS/#dataframes-v059-release-notes", 
            "text": "Track changes to JuliaLang/julia", 
            "title": "DataFrames v0.5.9 Release Notes"
        }, 
        {
            "location": "/NEWS/#dataframes-v058-release-notes", 
            "text": "", 
            "title": "DataFrames v0.5.8 Release Notes"
        }, 
        {
            "location": "/NEWS/#new-features_3", 
            "text": "Extends  StatsBase.predict  to take a DataFrame as a predictor ([#679])  coefnames  handles random-effect terms ([#662])", 
            "title": "New features"
        }, 
        {
            "location": "/NEWS/#deprecations_3", 
            "text": "Deprecates  DataFrame(::Dict, ...)  in favor of  convert  ([#626])", 
            "title": "Deprecations"
        }, 
        {
            "location": "/NEWS/#dataframes-v057-release-notes", 
            "text": "", 
            "title": "DataFrames v0.5.7 Release Notes"
        }, 
        {
            "location": "/NEWS/#new-features_4", 
            "text": "deleterows!(df::DataFrame, inds)  ([#635])", 
            "title": "New features"
        }, 
        {
            "location": "/NEWS/#changes_4", 
            "text": "empty!(::DataFrame)  and  insert!(::DataFrame, ...)  now operate in place ([#634])  All exported higher-order functions now handle do-block syntax ([#643])", 
            "title": "Changes"
        }, 
        {
            "location": "/NEWS/#dataframes-v056-release-notes", 
            "text": "Track changes to JuliaLang/julia", 
            "title": "DataFrames v0.5.6 Release Notes"
        }, 
        {
            "location": "/NEWS/#dataframes-v055-release-notes", 
            "text": "", 
            "title": "DataFrames v0.5.5 Release Notes"
        }, 
        {
            "location": "/NEWS/#new-features_5", 
            "text": "Support fitting arbitrary StatisticalModels ([#571])  Test coverage now tracked via Coveralls.io ([#597])", 
            "title": "New features"
        }, 
        {
            "location": "/NEWS/#changes_5", 
            "text": "show(::AbstractDataFrame)  now shows all columns by default", 
            "title": "Changes"
        }, 
        {
            "location": "/NEWS/#deprecations_4", 
            "text": "Deprecates  DataFrame(::Any...) ,  DataFrame(::Associative)  ([#610])", 
            "title": "Deprecations"
        }, 
        {
            "location": "/NEWS/#dataframes-v054-release-notes", 
            "text": "", 
            "title": "DataFrames v0.5.4 Release Notes"
        }, 
        {
            "location": "/NEWS/#new-features_6", 
            "text": "push!  methods add a row to a DataFrame ([#621])  Test coverage now tracked via Coveralls.io ([#597])", 
            "title": "New features"
        }, 
        {
            "location": "/NEWS/#changes_6", 
            "text": "IO functions ensure column names are valid symbols ([#563])  setindex!  methods now return the updated DataFrame", 
            "title": "Changes"
        }, 
        {
            "location": "/NEWS/#deprecations_5", 
            "text": "Deprecates  DataFrame(::Int, ::Int)  ([#561])", 
            "title": "Deprecations"
        }, 
        {
            "location": "/NEWS/#dataframes-v053-release-notes", 
            "text": "Internal changes to adjust to [JuliaLang/julia#5897]", 
            "title": "DataFrames v0.5.3 Release Notes"
        }, 
        {
            "location": "/NEWS/#dataframes-v052-release-notes", 
            "text": "Continues trend of stripping down features and improving core functionality.", 
            "title": "DataFrames v0.5.2 Release Notes"
        }, 
        {
            "location": "/NEWS/#new-features_7", 
            "text": "append!(::AbstractDataFrame, ::AbstractDataFrame)  ([#506])  join  supports  :semi -,  :anti - and  :cross -joins ([#524], [#536])  Implement  eltypes  argument in  readtable  ([#497])  Read from generic IO objects ([#499])", 
            "title": "New features"
        }, 
        {
            "location": "/NEWS/#changes_7", 
            "text": "Convert to using only symbols (no more strings) for column names ([#509])  Renames  stack_df ,  melt_df ,  pivot_table  to  stackdf ,  meltdf ,  pivottable  ([#538])  Renames  duplicated ,  drop_duplicates!  to  nonunique ,  unique!  ([#538])  Renames  load_df  to  loaddf  ([#538])  Renames  types  to  eltypes  ([#539])  Renames  readtable  argument  colnames  to  names  ([#497])", 
            "title": "Changes"
        }, 
        {
            "location": "/NEWS/#deprecations_6", 
            "text": "Removes expression-based indexing, including  with ,  within! ,  based_on , etc. ([#492])  Removes  DataStream  ([#492])  Removes  NamedArray  ([#492])  Removes column groupings ( set_groups ,  get_groups , etc.)  ([#492])  Removes specific colwise and rowwise functions ( rowsums ,  colnorms , etc.) ([#492])  Removes  @DataFrame  and  @transform  ([#492])  Deprecates natural  join s: the key must be specified now ([#536])", 
            "title": "Deprecations"
        }, 
        {
            "location": "/NEWS/#dataframes-v051-release-notes", 
            "text": "Removing prototype features until core functionality is farther along.", 
            "title": "DataFrames v0.5.1 Release Notes"
        }, 
        {
            "location": "/NEWS/#changes_8", 
            "text": "Write  Formula s without quoting, thanks to the  @~  macro ([JuliaLang/julia#4882])  Renames  EachCol ,  EachRow  to  eachcol ,  eachrow  ([#474])  eachrow  returns a  DataFrameRow  ([#474])  SubDataFrames  are now immutable ([#474])", 
            "title": "Changes"
        }, 
        {
            "location": "/NEWS/#deprecations_7", 
            "text": "Removes  IndexedVector  ([#483])  Removes  Blocks.jl  functionality ([#483])  Removes methods that treat DataFrame like a matrix, e.g  round ,  sin  ([#484])  Deprecates  sub 's alias  subset  ([#474])", 
            "title": "Deprecations"
        }, 
        {
            "location": "/NEWS/#dataframes-v050-release-notes", 
            "text": "Improved I/O and more-Julian idioms.", 
            "title": "DataFrames v0.5.0 Release Notes"
        }, 
        {
            "location": "/NEWS/#new-features_8", 
            "text": "Write HTML tables via writemime ([#433])  Read whitespace-delimited input ([#443])  Read input with C-style escapes ([#454])", 
            "title": "New features"
        }, 
        {
            "location": "/NEWS/#changes_9", 
            "text": "sort  interface updated to better match mainline Julia ([#389])  names! ,  rename! , and  delete!  now return the updated Index, rather than the names in the Index ([#445])  Renames  coltypes ,  colnames ,  clean_colnames!  to  types ,  names ,  cleannames!  ([#469])  Various improvements to  print / show  methods", 
            "title": "Changes"
        }, 
        {
            "location": "/NEWS/#deprecations_8", 
            "text": "Deprecates  rbind ,  cbind  and  vecbind  deprecated in favor of  hcat  and  vcat  ([#453])   [#389]: https://github.com/JuliaStats/DataFrames.jl/issues/389 [#433]: https://github.com/JuliaStats/DataFrames.jl/issues/433 [#443]: https://github.com/JuliaStats/DataFrames.jl/issues/443 [#445]: https://github.com/JuliaStats/DataFrames.jl/issues/445 [#453]: https://github.com/JuliaStats/DataFrames.jl/issues/453 [#454]: https://github.com/JuliaStats/DataFrames.jl/issues/454 [#469]: https://github.com/JuliaStats/DataFrames.jl/issues/469 [#474]: https://github.com/JuliaStats/DataFrames.jl/issues/474 [#483]: https://github.com/JuliaStats/DataFrames.jl/issues/483 [#484]: https://github.com/JuliaStats/DataFrames.jl/issues/484 [#492]: https://github.com/JuliaStats/DataFrames.jl/issues/492 [#497]: https://github.com/JuliaStats/DataFrames.jl/issues/497 [#499]: https://github.com/JuliaStats/DataFrames.jl/issues/499 [#506]: https://github.com/JuliaStats/DataFrames.jl/issues/506 [#509]: https://github.com/JuliaStats/DataFrames.jl/issues/509 [#524]: https://github.com/JuliaStats/DataFrames.jl/issues/524 [#536]: https://github.com/JuliaStats/DataFrames.jl/issues/536 [#538]: https://github.com/JuliaStats/DataFrames.jl/issues/538 [#539]: https://github.com/JuliaStats/DataFrames.jl/issues/539 [#561]: https://github.com/JuliaStats/DataFrames.jl/issues/561 [#563]: https://github.com/JuliaStats/DataFrames.jl/issues/563 [#571]: https://github.com/JuliaStats/DataFrames.jl/issues/571 [#597]: https://github.com/JuliaStats/DataFrames.jl/issues/597 [#610]: https://github.com/JuliaStats/DataFrames.jl/issues/610 [#621]: https://github.com/JuliaStats/DataFrames.jl/issues/621 [#626]: https://github.com/JuliaStats/DataFrames.jl/issues/626 [#634]: https://github.com/JuliaStats/DataFrames.jl/issues/634 [#635]: https://github.com/JuliaStats/DataFrames.jl/issues/635 [#643]: https://github.com/JuliaStats/DataFrames.jl/issues/643 [#662]: https://github.com/JuliaStats/DataFrames.jl/issues/662 [#679]: https://github.com/JuliaStats/DataFrames.jl/issues/679 [#700]: https://github.com/JuliaStats/DataFrames.jl/issues/700 [#725]: https://github.com/JuliaStats/DataFrames.jl/issues/725 [#726]: https://github.com/JuliaStats/DataFrames.jl/issues/726 [#734]: https://github.com/JuliaStats/DataFrames.jl/issues/734 [#747]: https://github.com/JuliaStats/DataFrames.jl/issues/747 [#749]: https://github.com/JuliaStats/DataFrames.jl/issues/749 [#751]: https://github.com/JuliaStats/DataFrames.jl/issues/751 [#752]: https://github.com/JuliaStats/DataFrames.jl/issues/752 [#754]: https://github.com/JuliaStats/DataFrames.jl/issues/754 [#755]: https://github.com/JuliaStats/DataFrames.jl/issues/755 [#759]: https://github.com/JuliaStats/DataFrames.jl/issues/759 [#790]: https://github.com/JuliaStats/DataFrames.jl/issues/790 [#806]: https://github.com/JuliaStats/DataFrames.jl/issues/806  [JuliaLang/julia#4882]: https://github.com/JuliaLang/julia/issues/4882 [JuliaLang/julia#5897]: https://github.com/JuliaLang/julia/issues/5897", 
            "title": "Deprecations"
        }, 
        {
            "location": "/LICENSE/", 
            "text": "DataFrames.jl is licensed under the MIT License:\n\n\n\n\nCopyright (c) 2012-2015: Harlan Harris, EPRI (Tom Short's code), Chris DuBois, John Myles White, and other contributors.\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.", 
            "title": "License"
        }
    ]
}